{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7082c8b7",
   "metadata": {},
   "source": [
    "# Deploy Trained Smolvla Policy\n",
    "\n",
    "<img src=\"./media/rollout3.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Deploy trained policy in simulation.\n",
    "# ========================================\n",
    "# 8.smolvla.ipynb - SmolVLA策略部署与测试\n",
    "# ========================================\n",
    "# 功能：加载训练好的SmolVLA模型，并在MuJoCo仿真环境中进行实际部署测试\n",
    "# SmolVLA = Small Vision-Language-Action Model（小型视觉-语言-动作模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - 设置环境变量(必须第一个运行)\n",
    "import os\n",
    "\n",
    "# 1. 设置DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"✓ DISPLAY设置为: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. 强制使用GPU渲染(关键!)\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGL后端GPU加速\n",
    "print(f\"✓ MUJOCO_GL: egl (GPU硬件加速)\")\n",
    "\n",
    "# 3. NVIDIA GPU优化\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # 关闭垂直同步\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # 减少CPU等待\n",
    "print(\"✓ NVIDIA GPU优化已启用\")\n",
    "\n",
    "# 4. OpenGL性能优化\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # 关闭抗锯齿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # 关闭各向异性过滤\n",
    "print(\"✓ OpenGL性能优化已启用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.50.3\n",
    "!pip install num2words\n",
    "!pip install accelerate\n",
    "!pip install safetensors>=0.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c036d1f",
   "metadata": {},
   "source": [
    "### [Optional] Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you want to use the collected dataset, please download it from Hugging Face.\n",
    "'''\n",
    "#!git clone https://huggingface.co/datasets/Jeongeun/omy_pnp_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07033fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download Jeongeun/omy_pnp_language --repo-type dataset --local-dir ./demo_data_language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246fa3e",
   "metadata": {},
   "source": [
    "## Step 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python train_model.py --config_path smolvla_omy.yaml\n",
    "from train_with_monitor_cell import train_with_monitor\n",
    "train_with_monitor(\"smolvla_omy.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20673462",
   "metadata": {},
   "source": [
    "## Step 3. Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07386e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import numpy as np\n",
    "from lerobot.common.datasets.utils import write_json, serialize_dict\n",
    "from lerobot.common.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "from lerobot.common.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.common.datasets.factory import resolve_delta_timestamps\n",
    "from lerobot.common.datasets.utils import dataset_to_policy_features\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1f651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381de80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./demo_data_language')\n",
    "except:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./omy_pnp_language')\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
    "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
    "# Temporal ensemble to make smoother trajectory predictions\n",
    "cfg = SmolVLAConfig(input_features=input_features, output_features=output_features, chunk_size= 5, n_action_steps=5)\n",
    "delta_timestamps = resolve_delta_timestamps(cfg, dataset_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmolVLAPolicy(\n",
       "  (normalize_inputs): Normalize(\n",
       "    (buffer_observation_state): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (normalize_targets): Normalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (unnormalize_outputs): Unnormalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (model): VLAFlowMatching(\n",
       "    (vlm_with_expert): SmolVLMWithExpertModel(\n",
       "      (vlm): SmolVLMForConditionalGeneration(\n",
       "        (model): SmolVLMModel(\n",
       "          (vision_model): SmolVLMVisionTransformer(\n",
       "            (embeddings): SmolVLMVisionEmbeddings(\n",
       "              (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
       "              (position_embedding): Embedding(1024, 768)\n",
       "            )\n",
       "            (encoder): SmolVLMEncoder(\n",
       "              (layers): ModuleList(\n",
       "                (0-11): 12 x SmolVLMEncoderLayer(\n",
       "                  (self_attn): SmolVLMVisionAttention(\n",
       "                    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                  (mlp): SmolVLMVisionMLP(\n",
       "                    (activation_fn): PytorchGELUTanh()\n",
       "                    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (connector): SmolVLMConnector(\n",
       "            (modality_projection): SmolVLMSimpleMLP(\n",
       "              (proj): Linear(in_features=12288, out_features=960, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (text_model): LlamaModel(\n",
       "            (embed_tokens): Embedding(49280, 960, padding_idx=2)\n",
       "            (layers): ModuleList(\n",
       "              (0-15): 16 x LlamaDecoderLayer(\n",
       "                (self_attn): LlamaAttention(\n",
       "                  (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                  (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                )\n",
       "                (mlp): LlamaMLP(\n",
       "                  (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "                  (act_fn): SiLU()\n",
       "                )\n",
       "                (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "                (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "              )\n",
       "            )\n",
       "            (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "        )\n",
       "        (lm_head): Linear(in_features=960, out_features=49280, bias=False)\n",
       "      )\n",
       "      (lm_expert): LlamaModel(\n",
       "        (embed_tokens): None\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (2): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (3): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (4): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (5): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (6): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (7): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (8): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (9): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (10): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (11): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (12): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (13): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (14): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (15): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (state_proj): Linear(in_features=32, out_features=960, bias=True)\n",
       "    (action_in_proj): Linear(in_features=32, out_features=720, bias=True)\n",
       "    (action_out_proj): Linear(in_features=720, out_features=32, bias=True)\n",
       "    (action_time_mlp_in): Linear(in_features=1440, out_features=720, bias=True)\n",
       "    (action_time_mlp_out): Linear(in_features=720, out_features=720, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We can now instantiate our policy with this config and the dataset stats.\n",
    "# policy = SmolVLAPolicy.from_pretrained('ckpt/smolvla_omy4060_20251103_224510/checkpoints/last/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# # You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# # policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "# policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmolVLAPolicy(\n",
       "  (normalize_inputs): Normalize(\n",
       "    (buffer_observation_state): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (normalize_targets): Normalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (unnormalize_outputs): Unnormalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (model): VLAFlowMatching(\n",
       "    (vlm_with_expert): SmolVLMWithExpertModel(\n",
       "      (vlm): SmolVLMForConditionalGeneration(\n",
       "        (model): SmolVLMModel(\n",
       "          (vision_model): SmolVLMVisionTransformer(\n",
       "            (embeddings): SmolVLMVisionEmbeddings(\n",
       "              (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
       "              (position_embedding): Embedding(1024, 768)\n",
       "            )\n",
       "            (encoder): SmolVLMEncoder(\n",
       "              (layers): ModuleList(\n",
       "                (0-11): 12 x SmolVLMEncoderLayer(\n",
       "                  (self_attn): SmolVLMVisionAttention(\n",
       "                    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                  (mlp): SmolVLMVisionMLP(\n",
       "                    (activation_fn): PytorchGELUTanh()\n",
       "                    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (connector): SmolVLMConnector(\n",
       "            (modality_projection): SmolVLMSimpleMLP(\n",
       "              (proj): Linear(in_features=12288, out_features=960, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (text_model): LlamaModel(\n",
       "            (embed_tokens): Embedding(49280, 960, padding_idx=2)\n",
       "            (layers): ModuleList(\n",
       "              (0-15): 16 x LlamaDecoderLayer(\n",
       "                (self_attn): LlamaAttention(\n",
       "                  (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                  (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                )\n",
       "                (mlp): LlamaMLP(\n",
       "                  (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "                  (act_fn): SiLU()\n",
       "                )\n",
       "                (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "                (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "              )\n",
       "            )\n",
       "            (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "        )\n",
       "        (lm_head): Linear(in_features=960, out_features=49280, bias=False)\n",
       "      )\n",
       "      (lm_expert): LlamaModel(\n",
       "        (embed_tokens): None\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (2): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (3): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (4): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (5): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (6): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (7): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (8): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (9): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (10): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (11): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (12): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (13): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (14): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (15): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (state_proj): Linear(in_features=32, out_features=960, bias=True)\n",
       "    (action_in_proj): Linear(in_features=32, out_features=720, bias=True)\n",
       "    (action_out_proj): Linear(in_features=720, out_features=32, bias=True)\n",
       "    (action_time_mlp_in): Linear(in_features=1440, out_features=720, bias=True)\n",
       "    (action_time_mlp_out): Linear(in_features=720, out_features=720, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #2000步微调结果测试 We can now instantiate our policy with this config and the dataset stats.\n",
    "# policy = SmolVLAPolicy.from_pretrained('ckpt/smolvla_omy4060_20251103_224510/checkpoints/002000/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# # You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# # policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "# policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10000步微调结果测试 We can now instantiate our policy with this config and the dataset stats.\n",
    "policy = SmolVLAPolicy.from_pretrained('ckpt/smolvla_omy4060_20251103_224510/checkpoints/010000/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e83f1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DISPLAY设置为: :0\n",
      "✓ MUJOCO_GL: egl (GPU硬件加速)\n",
      "✓ NVIDIA GPU优化已启用\n",
      "✓ OpenGL性能优化已启用\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - 设置环境变量(必须第一个运行)\n",
    "import os\n",
    "\n",
    "# 1. 设置DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"✓ DISPLAY设置为: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. 强制使用GPU渲染(关键!)\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGL后端GPU加速\n",
    "print(f\"✓ MUJOCO_GL: egl (GPU硬件加速)\")\n",
    "\n",
    "# 3. NVIDIA GPU优化\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # 关闭垂直同步\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # 减少CPU等待\n",
    "print(\"✓ NVIDIA GPU优化已启用\")\n",
    "\n",
    "# 4. OpenGL性能优化\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # 关闭抗锯齿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # 关闭各向异性过滤\n",
    "print(\"✓ OpenGL性能优化已启用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ebd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      " n_qpos:[31] n_qvel:[28] n_qacc:[28] n_ctrl:[10]\n",
      " integrator:[IMPLICITFAST]\n",
      "\n",
      "n_body:[23]\n",
      " [0/23] [world] mass:[0.00]kg\n",
      " [1/23] [front_object_table] mass:[1.00]kg\n",
      " [2/23] [camera] mass:[0.00]kg\n",
      " [3/23] [camera2] mass:[0.00]kg\n",
      " [4/23] [camera3] mass:[0.00]kg\n",
      " [5/23] [link1] mass:[2.06]kg\n",
      " [6/23] [link2] mass:[3.68]kg\n",
      " [7/23] [link3] mass:[2.39]kg\n",
      " [8/23] [link4] mass:[1.40]kg\n",
      " [9/23] [link5] mass:[1.40]kg\n",
      " [10/23] [link6] mass:[0.65]kg\n",
      " [11/23] [camera_center] mass:[0.00]kg\n",
      " [12/23] [tcp_link] mass:[0.32]kg\n",
      " [13/23] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/23] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/23] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/23] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/23] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/23] [object_mug_5] mass:[0.08]kg\n",
      " [19/23] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/23] [object_plate_11] mass:[0.10]kg\n",
      " [21/23] [body_obj_mug_6] mass:[0.00]kg\n",
      " [22/23] [object_mug_6] mass:[0.08]kg\n",
      "body_total_mass:[13.35]kg\n",
      "\n",
      "n_geom:[116]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_mesh:[112]\n",
      "mesh_names:['base_unit', 'link1', 'link2', 'link3', 'link4', 'link5', 'link6', 'flange', 'base', 'r1', 'r2', 'l1', 'l2', 'mug_5_normalized_0_vis', 'mug_5_normalized_collision_22._coll', 'mug_5_normalized_collision_23._coll', 'mug_5_normalized_collision_21._coll', 'mug_5_normalized_collision_20._coll', 'mug_5_normalized_collision_24._coll', 'mug_5_normalized_collision_30._coll', 'mug_5_normalized_collision_18._coll', 'mug_5_normalized_collision_19._coll', 'mug_5_normalized_collision_31._coll', 'mug_5_normalized_collision_25._coll', 'mug_5_normalized_collision_27._coll', 'mug_5_normalized_collision_26._coll', 'mug_5_normalized_collision_9._coll', 'mug_5_normalized_collision_8._coll', 'mug_5_normalized_collision_6._coll', 'mug_5_normalized_collision_7._coll', 'mug_5_normalized_collision_5._coll', 'mug_5_normalized_collision_4._coll', 'mug_5_normalized_collision_0._coll', 'mug_5_normalized_collision_1._coll', 'mug_5_normalized_collision_3._coll', 'mug_5_normalized_collision_2._coll', 'mug_5_normalized_collision_17._coll', 'mug_5_normalized_collision_16._coll', 'mug_5_normalized_collision_28._coll', 'mug_5_normalized_collision_14._coll', 'mug_5_normalized_collision_15._coll', 'mug_5_normalized_collision_29._coll', 'mug_5_normalized_collision_11._coll', 'mug_5_normalized_collision_10._coll', 'mug_5_normalized_collision_12._coll', 'mug_5_normalized_collision_13._coll', 'plate_11_normalized_0_vis', 'plate_11_normalized_collision_22._coll', 'plate_11_normalized_collision_23._coll', 'plate_11_normalized_collision_21._coll', 'plate_11_normalized_collision_20._coll', 'plate_11_normalized_collision_24._coll', 'plate_11_normalized_collision_30._coll', 'plate_11_normalized_collision_18._coll', 'plate_11_normalized_collision_19._coll', 'plate_11_normalized_collision_31._coll', 'plate_11_normalized_collision_25._coll', 'plate_11_normalized_collision_27._coll', 'plate_11_normalized_collision_26._coll', 'plate_11_normalized_collision_9._coll', 'plate_11_normalized_collision_8._coll', 'plate_11_normalized_collision_6._coll', 'plate_11_normalized_collision_7._coll', 'plate_11_normalized_collision_5._coll', 'plate_11_normalized_collision_4._coll', 'plate_11_normalized_collision_0._coll', 'plate_11_normalized_collision_1._coll', 'plate_11_normalized_collision_3._coll', 'plate_11_normalized_collision_2._coll', 'plate_11_normalized_collision_17._coll', 'plate_11_normalized_collision_16._coll', 'plate_11_normalized_collision_28._coll', 'plate_11_normalized_collision_14._coll', 'plate_11_normalized_collision_15._coll', 'plate_11_normalized_collision_29._coll', 'plate_11_normalized_collision_11._coll', 'plate_11_normalized_collision_10._coll', 'plate_11_normalized_collision_12._coll', 'plate_11_normalized_collision_13._coll', 'mug_6_normalized_0_vis', 'mug_6_normalized_collision_22._coll', 'mug_6_normalized_collision_23._coll', 'mug_6_normalized_collision_21._coll', 'mug_6_normalized_collision_20._coll', 'mug_6_normalized_collision_24._coll', 'mug_6_normalized_collision_30._coll', 'mug_6_normalized_collision_18._coll', 'mug_6_normalized_collision_19._coll', 'mug_6_normalized_collision_31._coll', 'mug_6_normalized_collision_25._coll', 'mug_6_normalized_collision_27._coll', 'mug_6_normalized_collision_26._coll', 'mug_6_normalized_collision_9._coll', 'mug_6_normalized_collision_8._coll', 'mug_6_normalized_collision_6._coll', 'mug_6_normalized_collision_7._coll', 'mug_6_normalized_collision_5._coll', 'mug_6_normalized_collision_4._coll', 'mug_6_normalized_collision_0._coll', 'mug_6_normalized_collision_1._coll', 'mug_6_normalized_collision_3._coll', 'mug_6_normalized_collision_2._coll', 'mug_6_normalized_collision_17._coll', 'mug_6_normalized_collision_16._coll', 'mug_6_normalized_collision_28._coll', 'mug_6_normalized_collision_14._coll', 'mug_6_normalized_collision_15._coll', 'mug_6_normalized_collision_29._coll', 'mug_6_normalized_collision_11._coll', 'mug_6_normalized_collision_10._coll', 'mug_6_normalized_collision_12._coll', 'mug_6_normalized_collision_13._coll']\n",
      "\n",
      "n_joint:[13]\n",
      " [0/13] [joint1] axis:[0. 0. 1.]\n",
      " [1/13] [joint2] axis:[0. 1. 0.]\n",
      " [2/13] [joint3] axis:[0. 1. 0.]\n",
      " [3/13] [joint4] axis:[0. 1. 0.]\n",
      " [4/13] [joint5] axis:[0. 0. 1.]\n",
      " [5/13] [joint6] axis:[0. 1. 0.]\n",
      " [6/13] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/13] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/13] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/13] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/13] [None] axis:[0. 0. 1.]\n",
      " [11/13] [None] axis:[0. 0. 1.]\n",
      " [12/13] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[28] (=number of rows of Jacobian)\n",
      " [0/28] [None] attached joint:[joint1] body:[link1]\n",
      " [1/28] [None] attached joint:[joint2] body:[link2]\n",
      " [2/28] [None] attached joint:[joint3] body:[link3]\n",
      " [3/28] [None] attached joint:[joint4] body:[link4]\n",
      " [4/28] [None] attached joint:[joint5] body:[link5]\n",
      " [5/28] [None] attached joint:[joint6] body:[link6]\n",
      " [6/28] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/28] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/28] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/28] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [22/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [23/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [24/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [25/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [26/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [27/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      "\n",
      "Free joint information. n_free_joint:[3]\n",
      " [0/3] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/3] [None] body_name_attached:[body_obj_plate_11]\n",
      " [2/3] [None] body_name_attached:[body_obj_mug_6]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[9]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11', 'bottom_site_mug_6', 'top_site_mug_6', 'horizontal_radius_site_mug_6']\n",
      "-----------------------------------------------------------------------------\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "from mujoco_env.y_env2 import SimpleEnv2\n",
    "xml_path = './asset/example_scene_y2.xml'\n",
    "PnPEnv = SimpleEnv2(xml_path, action_type='joint_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db761f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Approach 1: Using torchvision.transforms\n",
    "def get_default_transform(image_size: int = 224):\n",
    "    \"\"\"\n",
    "    Returns a torchvision transform that:\n",
    "     Converts to a FloatTensor and scales pixel values [0,255] -> [0.0,1.0]\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL [0–255] -> FloatTensor [0.0–1.0], shape C×H×W\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f070ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🚀 STARTING POLICY EVALUATION | 开始策略评估\n",
      "================================================================================\n",
      "Start Time | 开始时间: 2025-11-04 14:07:35\n",
      "Total Episodes | 总回合数: 100\n",
      "Timeout | 超时时间: 30s\n",
      "Control Frequency | 控制频率: 20Hz\n",
      "================================================================================\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 1/100 started... | 回合 1/100 开始... ✅ SUCCESS in 13.18s (134 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 2/100 started... | 回合 2/100 开始... ✅ SUCCESS in 16.80s (171 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 3/100 started... | 回合 3/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 4/100 started... | 回合 4/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 5/100 started... | 回合 5/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 6/100 started... | 回合 6/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 7/100 started... | 回合 7/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 8/100 started... | 回合 8/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 9/100 started... | 回合 9/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 10/100 started... | 回合 10/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "\n",
      "📊 Progress: 10/100 | Success Rate: 20.00% | 成功率: 20.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 11/100 started... | 回合 11/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 12/100 started... | 回合 12/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 13/100 started... | 回合 13/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 14/100 started... | 回合 14/100 开始... ✅ SUCCESS in 17.44s (179 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 15/100 started... | 回合 15/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 16/100 started... | 回合 16/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 17/100 started... | 回合 17/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 18/100 started... | 回合 18/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 19/100 started... | 回合 19/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 20/100 started... | 回合 20/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "\n",
      "📊 Progress: 20/100 | Success Rate: 15.00% | 成功率: 15.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 21/100 started... | 回合 21/100 开始... ✅ SUCCESS in 20.48s (210 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 22/100 started... | 回合 22/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 23/100 started... | 回合 23/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 24/100 started... | 回合 24/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 25/100 started... | 回合 25/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 26/100 started... | 回合 26/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 27/100 started... | 回合 27/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 28/100 started... | 回合 28/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 29/100 started... | 回合 29/100 开始... ✅ SUCCESS in 13.17s (135 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 30/100 started... | 回合 30/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "\n",
      "📊 Progress: 30/100 | Success Rate: 16.67% | 成功率: 16.67%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 31/100 started... | 回合 31/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 32/100 started... | 回合 32/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 33/100 started... | 回合 33/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 34/100 started... | 回合 34/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 35/100 started... | 回合 35/100 开始... ✅ SUCCESS in 17.71s (182 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 36/100 started... | 回合 36/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 37/100 started... | 回合 37/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 38/100 started... | 回合 38/100 开始... ✅ SUCCESS in 18.31s (186 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 39/100 started... | 回合 39/100 开始... ✅ SUCCESS in 17.31s (178 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 40/100 started... | 回合 40/100 开始... ✅ SUCCESS in 20.05s (204 steps) | 成功\n",
      "\n",
      "📊 Progress: 40/100 | Success Rate: 22.50% | 成功率: 22.50%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 41/100 started... | 回合 41/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 42/100 started... | 回合 42/100 开始... ✅ SUCCESS in 18.71s (191 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 43/100 started... | 回合 43/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 44/100 started... | 回合 44/100 开始... ✅ SUCCESS in 11.97s (123 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 45/100 started... | 回合 45/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 46/100 started... | 回合 46/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 47/100 started... | 回合 47/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 48/100 started... | 回合 48/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 49/100 started... | 回合 49/100 开始... ✅ SUCCESS in 18.01s (182 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 50/100 started... | 回合 50/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "\n",
      "📊 Progress: 50/100 | Success Rate: 24.00% | 成功率: 24.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 51/100 started... | 回合 51/100 开始... ✅ SUCCESS in 17.96s (183 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 52/100 started... | 回合 52/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 53/100 started... | 回合 53/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 54/100 started... | 回合 54/100 开始... ✅ SUCCESS in 16.88s (171 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 55/100 started... | 回合 55/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 56/100 started... | 回合 56/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 57/100 started... | 回合 57/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 58/100 started... | 回合 58/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 59/100 started... | 回合 59/100 开始... ✅ SUCCESS in 23.41s (238 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 60/100 started... | 回合 60/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "\n",
      "📊 Progress: 60/100 | Success Rate: 25.00% | 成功率: 25.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 61/100 started... | 回合 61/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 62/100 started... | 回合 62/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 63/100 started... | 回合 63/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 64/100 started... | 回合 64/100 开始... ✅ SUCCESS in 18.22s (188 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 65/100 started... | 回合 65/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 66/100 started... | 回合 66/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 67/100 started... | 回合 67/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 68/100 started... | 回合 68/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 69/100 started... | 回合 69/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 70/100 started... | 回合 70/100 开始... ✅ SUCCESS in 17.32s (178 steps) | 成功\n",
      "\n",
      "📊 Progress: 70/100 | Success Rate: 24.29% | 成功率: 24.29%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 71/100 started... | 回合 71/100 开始... ⏱️  TIMEOUT after 30.3s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 72/100 started... | 回合 72/100 开始... ✅ SUCCESS in 17.29s (179 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 73/100 started... | 回合 73/100 开始... ✅ SUCCESS in 17.21s (176 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 74/100 started... | 回合 74/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 75/100 started... | 回合 75/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 76/100 started... | 回合 76/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 77/100 started... | 回合 77/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 78/100 started... | 回合 78/100 开始... ✅ SUCCESS in 15.96s (165 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 79/100 started... | 回合 79/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 80/100 started... | 回合 80/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "\n",
      "📊 Progress: 80/100 | Success Rate: 25.00% | 成功率: 25.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 81/100 started... | 回合 81/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 82/100 started... | 回合 82/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 83/100 started... | 回合 83/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 84/100 started... | 回合 84/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 85/100 started... | 回合 85/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 86/100 started... | 回合 86/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 87/100 started... | 回合 87/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 88/100 started... | 回合 88/100 开始... ✅ SUCCESS in 26.59s (274 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 89/100 started... | 回合 89/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 90/100 started... | 回合 90/100 开始... ✅ SUCCESS in 17.53s (180 steps) | 成功\n",
      "\n",
      "📊 Progress: 90/100 | Success Rate: 24.44% | 成功率: 24.44%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 91/100 started... | 回合 91/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 92/100 started... | 回合 92/100 开始... ✅ SUCCESS in 16.18s (165 steps) | 成功\n",
      "DONE INITIALIZATION\n",
      "Episode 93/100 started... | 回合 93/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 94/100 started... | 回合 94/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 95/100 started... | 回合 95/100 开始... ⏱️  TIMEOUT after 30.3s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 96/100 started... | 回合 96/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 97/100 started... | 回合 97/100 开始... ⏱️  TIMEOUT after 30.0s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 98/100 started... | 回合 98/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 99/100 started... | 回合 99/100 开始... ⏱️  TIMEOUT after 30.1s | 超时\n",
      "DONE INITIALIZATION\n",
      "Episode 100/100 started... | 回合 100/100 开始... ⏱️  TIMEOUT after 30.2s | 超时\n",
      "\n",
      "📊 Progress: 100/100 | Success Rate: 23.00% | 成功率: 23.00%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "🎉 EVALUATION COMPLETED | 评估完成\n",
      "================================================================================\n",
      "End Time | 结束时间: 2025-11-04 14:53:03\n",
      "Total Duration | 总耗时: 2727.46s (45.46 minutes)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "📊 EVALUATION SUMMARY | 评估总结\n",
      "================================================================================\n",
      "\n",
      "📈 Overall Statistics | 总体统计:\n",
      "  Total Episodes | 总回合数:        100\n",
      "  Successful | 成功:               23\n",
      "  Failed | 失败:                   77\n",
      "  Timeout | 超时:                  77\n",
      "  Success Rate | 成功率:           23.00%\n",
      "\n",
      "⏱️  Time Statistics | 时间统计:\n",
      "  Average Duration | 平均耗时:    27.23s\n",
      "  Min Duration | 最短耗时:        11.97s\n",
      "  Max Duration | 最长耗时:        30.29s\n",
      "\n",
      "🎯 Step Statistics | 步数统计:\n",
      "  Average Steps | 平均步数:       278.9\n",
      "  Min Steps | 最少步数:           123\n",
      "  Max Steps | 最多步数:           317\n",
      "\n",
      "✅ Success Statistics | 成功回合统计:\n",
      "  Avg Steps (Success) | 成功平均步数: 181.4\n",
      "  Min Steps (Success) | 成功最少步数: 123\n",
      "  Max Steps (Success) | 成功最多步数: 274\n",
      "================================================================================\n",
      "\n",
      "📝 Results saved to: evaluation_results_20251104_140735.txt | 结果已保存到: evaluation_results_20251104_140735.txt\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# SmolVLA Policy Evaluation with Timeout and Success Rate Statistics\n",
    "# SmolVLA策略评估脚本（带超时机制和成功率统计）\n",
    "# ========================================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================================================================\n",
    "# Configuration | 配置参数\n",
    "# ========================================================================\n",
    "\n",
    "NUM_EPISODES = 100        # Total number of episodes to test | 测试回合总数\n",
    "TIMEOUT_SECONDS = 30      # Timeout for each episode (seconds) | 每回合超时时间（秒）\n",
    "CONTROL_FREQUENCY = 20    # Control frequency (Hz) | 控制频率（赫兹）\n",
    "MAX_STEPS_PER_EPISODE = TIMEOUT_SECONDS * CONTROL_FREQUENCY  # 最大步数 = 30秒 × 20Hz = 600步\n",
    "\n",
    "# ========================================================================\n",
    "# Statistics Container | 统计数据容器\n",
    "# ========================================================================\n",
    "\n",
    "class EvaluationStats:\n",
    "    \"\"\"\n",
    "    Container for evaluation statistics\n",
    "    评估统计数据容器\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_episodes = 0          # 总回合数\n",
    "        self.successful_episodes = 0     # 成功回合数\n",
    "        self.failed_episodes = 0         # 失败回合数\n",
    "        self.timeout_episodes = 0        # 超时回合数\n",
    "        self.episode_durations = []      # 每回合耗时列表\n",
    "        self.episode_steps = []          # 每回合步数列表\n",
    "        self.success_steps = []          # 成功回合的步数\n",
    "        \n",
    "    def add_episode(self, success, timeout, duration, steps):\n",
    "        \"\"\"\n",
    "        Add episode result to statistics\n",
    "        添加回合结果到统计数据\n",
    "        \n",
    "        Args:\n",
    "            success: Whether the episode succeeded | 是否成功\n",
    "            timeout: Whether the episode timed out | 是否超时\n",
    "            duration: Episode duration in seconds | 回合耗时（秒）\n",
    "            steps: Number of steps taken | 执行的步数\n",
    "        \"\"\"\n",
    "        self.total_episodes += 1\n",
    "        self.episode_durations.append(duration)\n",
    "        self.episode_steps.append(steps)\n",
    "        \n",
    "        if success:\n",
    "            self.successful_episodes += 1\n",
    "            self.success_steps.append(steps)\n",
    "        elif timeout:\n",
    "            self.timeout_episodes += 1\n",
    "            self.failed_episodes += 1\n",
    "        else:\n",
    "            self.failed_episodes += 1\n",
    "    \n",
    "    def get_success_rate(self):\n",
    "        \"\"\"Calculate success rate | 计算成功率\"\"\"\n",
    "        if self.total_episodes == 0:\n",
    "            return 0.0\n",
    "        return (self.successful_episodes / self.total_episodes) * 100\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"\n",
    "        Print evaluation summary\n",
    "        打印评估总结\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📊 EVALUATION SUMMARY | 评估总结\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\n📈 Overall Statistics | 总体统计:\")\n",
    "        print(f\"  Total Episodes | 总回合数:        {self.total_episodes}\")\n",
    "        print(f\"  Successful | 成功:               {self.successful_episodes}\")\n",
    "        print(f\"  Failed | 失败:                   {self.failed_episodes}\")\n",
    "        print(f\"  Timeout | 超时:                  {self.timeout_episodes}\")\n",
    "        print(f\"  Success Rate | 成功率:           {self.get_success_rate():.2f}%\")\n",
    "        \n",
    "        if self.episode_durations:\n",
    "            print(f\"\\n⏱️  Time Statistics | 时间统计:\")\n",
    "            print(f\"  Average Duration | 平均耗时:    {np.mean(self.episode_durations):.2f}s\")\n",
    "            print(f\"  Min Duration | 最短耗时:        {np.min(self.episode_durations):.2f}s\")\n",
    "            print(f\"  Max Duration | 最长耗时:        {np.max(self.episode_durations):.2f}s\")\n",
    "        \n",
    "        if self.episode_steps:\n",
    "            print(f\"\\n🎯 Step Statistics | 步数统计:\")\n",
    "            print(f\"  Average Steps | 平均步数:       {np.mean(self.episode_steps):.1f}\")\n",
    "            print(f\"  Min Steps | 最少步数:           {np.min(self.episode_steps)}\")\n",
    "            print(f\"  Max Steps | 最多步数:           {np.max(self.episode_steps)}\")\n",
    "        \n",
    "        if self.success_steps:\n",
    "            print(f\"\\n✅ Success Statistics | 成功回合统计:\")\n",
    "            print(f\"  Avg Steps (Success) | 成功平均步数: {np.mean(self.success_steps):.1f}\")\n",
    "            print(f\"  Min Steps (Success) | 成功最少步数: {np.min(self.success_steps)}\")\n",
    "            print(f\"  Max Steps (Success) | 成功最多步数: {np.max(self.success_steps)}\")\n",
    "        \n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ========================================================================\n",
    "# Main Evaluation Loop | 主评估循环\n",
    "# ========================================================================\n",
    "\n",
    "def evaluate_policy_with_timeout():\n",
    "    \"\"\"\n",
    "    Evaluate policy performance with timeout mechanism\n",
    "    评估策略性能（带超时机制）\n",
    "    \"\"\"\n",
    "    # 初始化统计对象 Initialize statistics object\n",
    "    stats = EvaluationStats()\n",
    "    \n",
    "    # 记录开始时间 Record start time\n",
    "    evaluation_start_time = datetime.now()\n",
    "    print(\"=\"*80)\n",
    "    print(\"🚀 STARTING POLICY EVALUATION | 开始策略评估\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Start Time | 开始时间: {evaluation_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total Episodes | 总回合数: {NUM_EPISODES}\")\n",
    "    print(f\"Timeout | 超时时间: {TIMEOUT_SECONDS}s\")\n",
    "    print(f\"Control Frequency | 控制频率: {CONTROL_FREQUENCY}Hz\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Episode Loop | 回合循环\n",
    "    # ====================================================================\n",
    "    for episode_idx in range(NUM_EPISODES):\n",
    "        # 重置环境和策略 Reset environment and policy\n",
    "        PnPEnv.reset(seed=episode_idx)  # 使用不同的seed确保多样性 Use different seed for diversity\n",
    "        policy.reset()\n",
    "        policy.eval()\n",
    "        \n",
    "        # 初始化回合变量 Initialize episode variables\n",
    "        step = 0                           # 当前步数计数器 Current step counter\n",
    "        episode_start_time = time.time()   # 回合开始时间 Episode start time\n",
    "        episode_success = False            # 成功标志 Success flag\n",
    "        episode_timeout = False            # 超时标志 Timeout flag\n",
    "        \n",
    "        print(f\"Episode {episode_idx + 1}/{NUM_EPISODES} started... | 回合 {episode_idx + 1}/{NUM_EPISODES} 开始...\", end=\" \")\n",
    "        \n",
    "        # ================================================================\n",
    "        # Step Loop | 步骤循环\n",
    "        # ================================================================\n",
    "        while PnPEnv.env.is_viewer_alive():\n",
    "            # 推进物理仿真 Advance physics simulation\n",
    "            PnPEnv.step_env()\n",
    "            \n",
    "            # 按控制频率执行（20Hz = 每秒20次）\n",
    "            # Execute at control frequency (20Hz = 20 times per second)\n",
    "            if PnPEnv.env.loop_every(HZ=CONTROL_FREQUENCY):\n",
    "                \n",
    "                # ========================================================\n",
    "                # Timeout Check | 超时检查\n",
    "                # ========================================================\n",
    "                current_time = time.time()\n",
    "                elapsed_time = current_time - episode_start_time\n",
    "                \n",
    "                if elapsed_time > TIMEOUT_SECONDS:\n",
    "                    episode_timeout = True\n",
    "                    print(f\"⏱️  TIMEOUT after {elapsed_time:.1f}s | 超时\")\n",
    "                    break\n",
    "                \n",
    "                # ========================================================\n",
    "                # Success Check | 成功检查\n",
    "                # ========================================================\n",
    "                success = PnPEnv.check_success()\n",
    "                if success:\n",
    "                    episode_success = True\n",
    "                    episode_duration = time.time() - episode_start_time\n",
    "                    print(f\"✅ SUCCESS in {episode_duration:.2f}s ({step} steps) | 成功\")\n",
    "                    break\n",
    "                \n",
    "                # ========================================================\n",
    "                # State Observation | 状态观测\n",
    "                # ========================================================\n",
    "                # 获取机器人关节状态（前6个关节）\n",
    "                # Get robot joint states (first 6 joints)\n",
    "                state = PnPEnv.get_joint_state()[:6]\n",
    "                \n",
    "                # ========================================================\n",
    "                # Image Observation | 图像观测\n",
    "                # ========================================================\n",
    "                # 获取两个摄像头的图像：第三人称视角 + 腕部视角\n",
    "                # Get images from two cameras: third-person view + wrist view\n",
    "                image, wrist_image = PnPEnv.grab_image()\n",
    "                \n",
    "                # 图像预处理：PIL格式 -> 调整大小 -> Tensor\n",
    "                # Image preprocessing: PIL format -> Resize -> Tensor\n",
    "                image = Image.fromarray(image)           # NumPy数组转PIL图像 NumPy array to PIL image\n",
    "                image = image.resize((256, 256))         # 调整到256x256 Resize to 256x256\n",
    "                image = IMG_TRANSFORM(image)             # 转为Tensor [0,1] Convert to Tensor [0,1]\n",
    "                \n",
    "                wrist_image = Image.fromarray(wrist_image)\n",
    "                wrist_image = wrist_image.resize((256, 256))\n",
    "                wrist_image = IMG_TRANSFORM(wrist_image)\n",
    "                \n",
    "                # ========================================================\n",
    "                # Prepare Model Input | 准备模型输入\n",
    "                # ========================================================\n",
    "                data = {\n",
    "                    # 关节状态：[1, 6] 张量 Joint state: [1, 6] tensor\n",
    "                    'observation.state': torch.tensor([state]).to(device),\n",
    "                    \n",
    "                    # 第三人称图像：[1, 3, 256, 256] 张量 Third-person image: [1, 3, 256, 256] tensor\n",
    "                    'observation.image': image.unsqueeze(0).to(device),\n",
    "                    \n",
    "                    # 腕部图像：[1, 3, 256, 256] 张量 Wrist image: [1, 3, 256, 256] tensor\n",
    "                    'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
    "                    \n",
    "                    # 任务描述（自然语言）Task description (natural language)\n",
    "                    'task': [PnPEnv.instruction],  # 例如：\"pick the mug\" or \"place the plate\"\n",
    "                }\n",
    "                \n",
    "                # ========================================================\n",
    "                # Policy Inference | 策略推理\n",
    "                # ========================================================\n",
    "                # 模型预测动作（无梯度计算）\n",
    "                # Model predicts action (no gradient computation)\n",
    "                with torch.no_grad():\n",
    "                    action = policy.select_action(data)  # 输出shape: [1, chunk_size, 7]\n",
    "                    action = action[0, :7].cpu().numpy() # 取第一步动作: [7]\n",
    "                \n",
    "                # 动作维度说明 Action dimensions:\n",
    "                # action[0:6] - 6个关节的目标角度或角度增量 6 joint angles or increments\n",
    "                # action[6]   - 夹爪开合状态 Gripper open/close state\n",
    "                \n",
    "                # ========================================================\n",
    "                # Execute Action | 执行动作\n",
    "                # ========================================================\n",
    "                _ = PnPEnv.step(action)\n",
    "                \n",
    "                # ========================================================\n",
    "                # Render Visualization | 渲染可视化\n",
    "                # ========================================================\n",
    "                PnPEnv.render()\n",
    "                \n",
    "                # 步数递增 Increment step counter\n",
    "                step += 1\n",
    "                \n",
    "                # 步数限制检查（防止无限循环）\n",
    "                # Step limit check (prevent infinite loop)\n",
    "                if step >= MAX_STEPS_PER_EPISODE:\n",
    "                    episode_timeout = True\n",
    "                    print(f\"⏱️  MAX STEPS REACHED | 达到最大步数\")\n",
    "                    break\n",
    "        \n",
    "        # ================================================================\n",
    "        # Episode End | 回合结束\n",
    "        # ================================================================\n",
    "        episode_duration = time.time() - episode_start_time\n",
    "        \n",
    "        # 记录统计数据 Record statistics\n",
    "        stats.add_episode(\n",
    "            success=episode_success,\n",
    "            timeout=episode_timeout,\n",
    "            duration=episode_duration,\n",
    "            steps=step\n",
    "        )\n",
    "        \n",
    "        # 每10回合打印进度 Print progress every 10 episodes\n",
    "        if (episode_idx + 1) % 10 == 0:\n",
    "            current_success_rate = stats.get_success_rate()\n",
    "            print(f\"\\n📊 Progress: {episode_idx + 1}/{NUM_EPISODES} | \"\n",
    "                  f\"Success Rate: {current_success_rate:.2f}% | \"\n",
    "                  f\"成功率: {current_success_rate:.2f}%\\n\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Evaluation Complete | 评估完成\n",
    "    # ====================================================================\n",
    "    evaluation_end_time = datetime.now()\n",
    "    total_duration = (evaluation_end_time - evaluation_start_time).total_seconds()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🎉 EVALUATION COMPLETED | 评估完成\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"End Time | 结束时间: {evaluation_end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total Duration | 总耗时: {total_duration:.2f}s ({total_duration/60:.2f} minutes)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 打印详细统计 Print detailed statistics\n",
    "    stats.print_summary()\n",
    "    \n",
    "    # 保存结果到文件 Save results to file\n",
    "    save_evaluation_results(stats, evaluation_start_time, evaluation_end_time)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# ========================================================================\n",
    "# Save Results to File | 保存结果到文件\n",
    "# ========================================================================\n",
    "\n",
    "def save_evaluation_results(stats, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Save evaluation results to a text file\n",
    "    保存评估结果到文本文件\n",
    "    \"\"\"\n",
    "    timestamp = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"evaluation_results_{timestamp}.txt\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"SmolVLA Policy Evaluation Results\\n\")\n",
    "        f.write(\"SmolVLA策略评估结果\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Start Time | 开始时间: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"End Time | 结束时间: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Duration | 总耗时: {(end_time - start_time).total_seconds():.2f}s\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Episodes | 总回合数: {stats.total_episodes}\\n\")\n",
    "        f.write(f\"Successful | 成功: {stats.successful_episodes}\\n\")\n",
    "        f.write(f\"Failed | 失败: {stats.failed_episodes}\\n\")\n",
    "        f.write(f\"Timeout | 超时: {stats.timeout_episodes}\\n\")\n",
    "        f.write(f\"Success Rate | 成功率: {stats.get_success_rate():.2f}%\\n\\n\")\n",
    "        \n",
    "        if stats.episode_durations:\n",
    "            f.write(f\"Average Duration | 平均耗时: {np.mean(stats.episode_durations):.2f}s\\n\")\n",
    "            f.write(f\"Average Steps | 平均步数: {np.mean(stats.episode_steps):.1f}\\n\")\n",
    "        \n",
    "        if stats.success_steps:\n",
    "            f.write(f\"Average Steps (Success) | 成功平均步数: {np.mean(stats.success_steps):.1f}\\n\")\n",
    "    \n",
    "    print(f\"📝 Results saved to: {filename} | 结果已保存到: {filename}\")\n",
    "\n",
    "# ========================================================================\n",
    "# Execute Evaluation | 执行评估\n",
    "# ========================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 运行评估 Run evaluation\n",
    "    evaluation_stats = evaluate_policy_with_timeout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b593df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.push_to_hub(\n",
    "#     repo_id='Jeongeun/omy_pnp_smolvla',\n",
    "#     commit_message='Add trained policy for PnP task',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9cb9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
