{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7082c8b7",
   "metadata": {},
   "source": [
    "# Deploy Trained Smolvla Policy\n",
    "\n",
    "<img src=\"./media/rollout3.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Deploy trained policy in simulation.\n",
    "# ========================================\n",
    "# 8.smolvla.ipynb - SmolVLA策略部署与测试\n",
    "# ========================================\n",
    "# 功能：加载训练好的SmolVLA模型，并在MuJoCo仿真环境中进行实际部署测试\n",
    "# SmolVLA = Small Vision-Language-Action Model（小型视觉-语言-动作模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - 设置环境变量(必须第一个运行)\n",
    "import os\n",
    "\n",
    "# 1. 设置DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"✓ DISPLAY设置为: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. 强制使用GPU渲染(关键!)\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGL后端GPU加速\n",
    "print(f\"✓ MUJOCO_GL: egl (GPU硬件加速)\")\n",
    "\n",
    "# 3. NVIDIA GPU优化\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # 关闭垂直同步\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # 减少CPU等待\n",
    "print(\"✓ NVIDIA GPU优化已启用\")\n",
    "\n",
    "# 4. OpenGL性能优化\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # 关闭抗锯齿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # 关闭各向异性过滤\n",
    "print(\"✓ OpenGL性能优化已启用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.50.3\n",
    "!pip install num2words\n",
    "!pip install accelerate\n",
    "!pip install safetensors>=0.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c036d1f",
   "metadata": {},
   "source": [
    "### [Optional] Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you want to use the collected dataset, please download it from Hugging Face.\n",
    "'''\n",
    "#!git clone https://huggingface.co/datasets/Jeongeun/omy_pnp_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07033fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download Jeongeun/omy_pnp_language --repo-type dataset --local-dir ./demo_data_language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246fa3e",
   "metadata": {},
   "source": [
    "## Step 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python train_model.py --config_path smolvla_omy.yaml\n",
    "from train_with_monitor_cell import train_with_monitor\n",
    "train_with_monitor(\"smolvla_omy.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20673462",
   "metadata": {},
   "source": [
    "## Step 3. Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07386e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import numpy as np\n",
    "from lerobot.common.datasets.utils import write_json, serialize_dict\n",
    "from lerobot.common.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "from lerobot.common.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.common.datasets.factory import resolve_delta_timestamps\n",
    "from lerobot.common.datasets.utils import dataset_to_policy_features\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381de80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./demo_data_language')\n",
    "except:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./omy_pnp_language')\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
    "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
    "# Temporal ensemble to make smoother trajectory predictions\n",
    "cfg = SmolVLAConfig(input_features=input_features, output_features=output_features, chunk_size= 5, n_action_steps=5)\n",
    "delta_timestamps = resolve_delta_timestamps(cfg, dataset_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now instantiate our policy with this config and the dataset stats.\n",
    "policy = SmolVLAPolicy.from_pretrained('ckpt/smolvla_omy_20251103_140619/checkpoints/last/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco_env.y_env2 import SimpleEnv2\n",
    "xml_path = './asset/example_scene_y2.xml'\n",
    "PnPEnv = SimpleEnv2(xml_path, action_type='joint_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db761f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Approach 1: Using torchvision.transforms\n",
    "def get_default_transform(image_size: int = 224):\n",
    "    \"\"\"\n",
    "    Returns a torchvision transform that:\n",
    "     Converts to a FloatTensor and scales pixel values [0,255] -> [0.0,1.0]\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL [0–255] -> FloatTensor [0.0–1.0], shape C×H×W\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "PnPEnv.reset(seed=0)\n",
    "policy.reset()\n",
    "policy.eval()\n",
    "save_image = True\n",
    "IMG_TRANSFORM = get_default_transform()\n",
    "while PnPEnv.env.is_viewer_alive():\n",
    "    PnPEnv.step_env()\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        # Check if the task is completed\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            # Reset the environment and action queue\n",
    "            policy.reset()\n",
    "            PnPEnv.reset()\n",
    "            step = 0\n",
    "            save_image = False\n",
    "        # Get the current state of the environment\n",
    "        state = PnPEnv.get_joint_state()[:6]\n",
    "        # Get the current image from the environment\n",
    "        image, wirst_image = PnPEnv.grab_image()\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((256, 256))\n",
    "        image = IMG_TRANSFORM(image)\n",
    "        wrist_image = Image.fromarray(wirst_image)\n",
    "        wrist_image = wrist_image.resize((256, 256))\n",
    "        wrist_image = IMG_TRANSFORM(wrist_image)\n",
    "        data = {\n",
    "            'observation.state': torch.tensor([state]).to(device),\n",
    "            'observation.image': image.unsqueeze(0).to(device),\n",
    "            'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
    "            'task': [PnPEnv.instruction],\n",
    "        }\n",
    "        # Select an action\n",
    "        action = policy.select_action(data)\n",
    "        action = action[0,:7].cpu().detach().numpy()\n",
    "        # Take a step in the environment\n",
    "        _ = PnPEnv.step(action)\n",
    "        PnPEnv.render()\n",
    "        step += 1\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b593df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.push_to_hub(\n",
    "#     repo_id='Jeongeun/omy_pnp_smolvla',\n",
    "#     commit_message='Add trained policy for PnP task',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
