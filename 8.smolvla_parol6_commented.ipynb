{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7082c8b7",
   "metadata": {},
   "source": [
    "# Deploy Trained Smolvla Policy\n",
    "\n",
    "<img src=\"./media/rollout3.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Deploy trained policy in simulation.\n",
    "# ========================================\n",
    "# 8.smolvla.ipynb - SmolVLA策略部署与测试\n",
    "# ========================================\n",
    "# 功能：加载训练好的SmolVLA模型，并在MuJoCo仿真环境中进行实际部署测试\n",
    "# SmolVLA = Small Vision-Language-Action Model（小型视觉-语言-动作模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f883bd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DISPLAY设置为: :0\n",
      "✓ MUJOCO_GL: egl (GPU硬件加速)\n",
      "✓ NVIDIA GPU优化已启用\n",
      "✓ OpenGL性能优化已启用\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1: 环境变量配置(必须首先运行)\n",
    "# ==========================================\n",
    "import os\n",
    "# 1. X11显示配置\n",
    "os.environ['DISPLAY'] = ':0'  # X服务器显示编号\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')  # X认证文件\n",
    "print(f\"✓ DISPLAY设置为: {os.environ['DISPLAY']}\")\n",
    "# 2. MuJoCo GPU渲染\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGL后端GPU加速\n",
    "print(f\"✓ MUJOCO_GL: egl (GPU硬件加速)\")\n",
    "# 3. NVIDIA GPU优化\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # 关闭垂直同步\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'  # 减少CPU等待\n",
    "print(\"✓ NVIDIA GPU优化已启用\")\n",
    "# 4. OpenGL性能优化\n",
    "os.environ['__GL_FSAA_MODE'] = '0'  # 关闭抗锯齿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'  # 关闭各向异性过滤\n",
    "print(\"✓ OpenGL性能优化已启用\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab95e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.50.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (4.50.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (6.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (25.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (0.21.4)\n",
      "Requirement already satisfied: requests in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (4.67.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (2.2.6)\n",
      "Requirement already satisfied: filelock in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (3.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (2025.10.23)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (2025.10.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (3.4.4)\n",
      "Requirement already satisfied: num2words in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (0.5.14)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from num2words) (0.6.2)\n",
      "Requirement already satisfied: accelerate in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: pyyaml in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: psutil in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (7.1.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: filelock in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: jinja2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 2: 安装Python依赖包\n",
    "# ==========================================\n",
    "# transformers: HuggingFace库,包含SmolVLA\n",
    "!pip install transformers==4.50.3\n",
    "# num2words: 数字转文字\n",
    "!pip install num2words\n",
    "# accelerate: 模型加速\n",
    "!pip install accelerate\n",
    "# safetensors: 模型序列化\n",
    "!pip install safetensors>=0.4.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c036d1f",
   "metadata": {},
   "source": [
    "### [Optional] Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c3d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: 目标路径 'omy_pnp_language' 已经存在，并且不是一个空目录。\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 3: [可选]下载数据集\n",
    "# ==========================================\n",
    "# 从HuggingFace克隆数据集\n",
    "!git clone https://huggingface.co/datasets/Jeongeun/omy_pnp_language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07033fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
      "Fetching 25 files:   0%|                                 | 0/25 [00:00<?, ?it/s]Downloading 'data/chunk-000/episode_000003.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/I4KmEhnhp7DGsGV1cF9fTGwH1Z8=.944ca1dc37f36c1fd7d6e04f5af79b451af3014d23b92a23c629f8123995f3af.incomplete'\n",
      "Downloading 'data/chunk-000/episode_000005.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/-SK4qvRTwf8GI3UnEqFxvRjn4fA=.0714c8b49a8d6ca430fb4effba02fb2ea737506a356a62a7b4d802f81622b303.incomplete'\n",
      "Downloading 'data/chunk-000/episode_000004.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/jFtolRe5Vvw8HkW1jrJcK1IP93I=.41c838a912c8c245642bb5526a58bcf28812185f91be45d1bc69e2606b5f0c82.incomplete'\n",
      "Downloading 'data/chunk-000/episode_000001.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/VextNUIRmXdKTDFi2d6W2hth3P4=.b6e877c248d4597f8efa7c8731cbcfb23bc4ef6cd69229a6382eef31d8aa56c8.incomplete'\n",
      "Downloading 'data/chunk-000/episode_000002.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/OSyyJRwGKrO_YFS2cpjykP4P8nE=.892cdf8ad86165cc121efc0bce7307b885a3a4b49364822dcfb9cf7ce8716995.incomplete'\n",
      "Downloading 'data/chunk-000/episode_000006.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/oo-hXxuwhJ7RGGbeILD7o43Hu6o=.9c783654ace629e284a8fee1067efeeb1db5517f54c717b7cb9e1fc082df65ac.incomplete'\n",
      "\n",
      "data/chunk-000/episode_000003.parquet:   0%|        | 0.00/16.1M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:   0%|        | 0.00/23.0M [00:00<?, ?B/s]\u001b[A\u001b[ADownloading '.gitattributes' to 'demo_data_language/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.1ef325f1b111266a6b26e0196871bd78baa8c2f3.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:   0%|        | 0.00/24.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:   0%|        | 0.00/26.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   0%|        | 0.00/23.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000000.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/cNsBuwyxGLgaOECPx2lW57L780o=.650700f861c5ab924302c2d55d3e79c511b0ebd14aefd246cad071e7b83fb771.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".gitattributes: 2.46kB [00:00, 14.9MB/s]A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/.gitattributes\n",
      "Fetching 25 files:   4%|█                        | 1/25 [00:01<00:33,  1.38s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:   0%|        | 0.00/21.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000007.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/1d533h4ypW6i_-P9ejcguxrCaPM=.3e8c9bccebec5670641256ae432835a98b2dc547f150e3f692e7fd71ebe41372.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:   0%|        | 0.00/13.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:   0%|        | 0.00/14.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:   0%| | 20.6k/16.1M [00:02<33:18, 8.05kB/\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:   1%| | 149k/16.1M [00:03<04:35, 57.9kB/s\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:   2%| | 308k/16.1M [00:03<01:59, 133kB/s]\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:   0%| | 31.2k/23.0M [00:03<40:36, 9.44kB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   0%| | 10.3k/23.1M [00:03<2:04:33, 3.09k\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:   5%| | 841k/16.1M [00:03<00:34, 442kB/s]\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:   0%| | 58.5k/23.0M [00:03<20:21, 18.8kB/\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:   9%| | 1.48M/16.1M [00:03<00:16, 872kB/s\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  12%| | 1.99M/16.1M [00:04<00:13, 1.05MB/\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:   2%| | 451k/23.0M [00:04<02:02, 184kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:   0%| | 47.0k/24.1M [00:03<33:13, 12.1kB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:   7%| | 1.59M/23.0M [00:04<00:29, 727kB/s\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  16%|▏| 3.59M/23.0M [00:04<00:10, 1.93MB/\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  26%|▎| 4.18M/16.1M [00:04<00:05, 2.16MB/\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  20%|▏| 4.65M/23.0M [00:04<00:07, 2.45MB/\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  31%|▎| 5.01M/16.1M [00:04<00:04, 2.47MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:   0%| | 99.9k/21.4M [00:04<16:52, 21.0kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  30%|▎| 6.90M/23.0M [00:05<00:05, 3.07MB/\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  44%|▍| 7.05M/16.1M [00:05<00:03, 2.56MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   0%| | 21.6k/23.1M [00:05<1:32:06, 4.18k\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  35%|▎| 8.06M/23.0M [00:05<00:04, 3.33MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:   1%| | 320k/21.4M [00:05<04:28, 78.4kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:   4%| | 521k/14.2M [00:04<02:10, 104kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  57%|▌| 9.23M/16.1M [00:05<00:01, 3.68MB/\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  40%|▍| 9.26M/23.0M [00:05<00:03, 3.78MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:   1%| | 350k/26.2M [00:05<06:57, 62.0kB/s\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:   5%| | 1.10M/21.4M [00:05<00:57, 351kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:   2%| | 535k/24.1M [00:05<03:24, 116kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   1%| | 227k/23.1M [00:05<05:51, 65.2kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:   5%| | 1.21M/26.2M [00:05<01:34, 264kB/s\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  54%|▌| 12.5M/23.0M [00:06<00:01, 6.03MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:   3%| | 380k/13.9M [00:05<03:18, 68.3kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:   7%| | 1.56M/21.4M [00:05<00:43, 456kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:   6%| | 916k/14.2M [00:05<01:10, 187kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:   2%| | 555k/24.1M [00:06<03:45, 104kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  58%|▌| 13.2M/23.0M [00:06<00:02, 4.00MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  10%| | 1.44M/13.9M [00:06<00:41, 301kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   2%| | 473k/23.1M [00:06<03:09, 119kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  64%|▋| 14.8M/23.0M [00:06<00:01, 4.41MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:   6%| | 1.52M/26.2M [00:06<01:25, 289kB/s\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:   8%| | 1.19M/14.2M [00:06<00:56, 229kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  12%| | 1.60M/13.9M [00:06<00:41, 300kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:   7%| | 1.93M/26.2M [00:07<01:04, 374kB/s\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  70%|▋| 11.3M/16.1M [00:07<00:02, 2.22MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:   8%| | 1.78M/21.4M [00:06<00:52, 371kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  17%|▏| 2.46M/14.2M [00:06<00:17, 658kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:   4%| | 869k/24.1M [00:07<02:23, 162kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  72%|▋| 16.7M/23.0M [00:07<00:01, 3.81MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:   9%| | 2.31M/26.2M [00:07<00:46, 517kB/s\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:   4%| | 889k/24.1M [00:07<02:26, 159kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  18%|▏| 2.57M/13.9M [00:07<00:19, 588kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   3%| | 635k/23.1M [00:07<02:37, 143kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  13%|▏| 2.71M/21.4M [00:07<00:24, 759kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  23%|▏| 3.29M/14.2M [00:06<00:11, 972kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet:  83%|▊| 13.3M/16.1M [00:07<00:00, 2.95MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  16%|▏| 4.12M/26.2M [00:07<00:14, 1.52MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet:  90%|▉| 20.6M/23.0M [00:07<00:00, 6.66MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:   4%| | 1.02M/23.1M [00:07<01:13, 302kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  20%|▏| 4.34M/21.4M [00:07<00:10, 1.55MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  20%|▏| 2.78M/13.9M [00:07<00:19, 570kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  29%|▎| 4.05M/14.2M [00:07<00:09, 1.10MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000004.parquet: 100%|█| 23.0M/23.0M [00:08<00:00, 2.82MB/\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000004.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  12%| | 2.83M/23.1M [00:07<00:17, 1.13MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  19%|▏| 4.96M/26.2M [00:08<00:14, 1.46MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  22%|▏| 4.74M/21.4M [00:07<00:12, 1.39MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  10%| | 2.48M/24.1M [00:08<00:30, 717kB/s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  24%|▏| 5.65M/23.1M [00:08<00:06, 2.77MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000003.parquet: 100%|█| 16.1M/16.1M [00:08<00:00, 1.89MB/\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000003.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  33%|▎| 4.74M/14.2M [00:07<00:07, 1.19MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000008.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/FNURp8HeA8-i1yewJ18DZKy6hBE=.10434392182667ee9289d147d79b55de2d379a81a391fe5d176c4a1567d0680d.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  20%|▏| 4.94M/24.1M [00:08<00:10, 1.78MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  29%|▎| 7.73M/26.2M [00:08<00:06, 2.82MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  29%|▎| 6.10M/21.4M [00:08<00:07, 2.04MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  27%|▎| 6.35M/23.1M [00:08<00:06, 2.69MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000009.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/L1U0W438Fu_YRcBknvo4psb4yGo=.8e87f114e023e2c3cecc2f864342746830a0bba859cf29941b0a206bdf2a8a8c.incomplete'\n",
      "\n",
      "data/chunk-000/episode_000008.parquet:   0%|        | 0.00/23.6M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:   0%|        | 0.00/23.3M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  27%|▎| 6.44M/24.1M [00:08<00:08, 2.09MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  35%|▎| 4.85M/13.9M [00:08<00:08, 1.07MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  33%|▎| 7.66M/23.1M [00:09<00:06, 2.32MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  34%|▎| 8.87M/26.2M [00:09<00:07, 2.29MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  50%|▍| 7.08M/14.2M [00:08<00:03, 1.86MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  55%|▌| 7.83M/14.2M [00:08<00:03, 2.07MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  35%|▎| 8.55M/24.1M [00:09<00:05, 2.61MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  43%|▍| 11.3M/26.2M [00:09<00:04, 3.12MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  43%|▍| 5.92M/13.9M [00:09<00:06, 1.19MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  38%|▍| 9.20M/24.1M [00:09<00:05, 2.65MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  77%|▊| 11.0M/14.2M [00:09<00:00, 3.83MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet:  92%|▉| 13.1M/14.2M [00:09<00:00, 4.92MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  30%|▎| 6.45M/21.4M [00:09<00:15, 982kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  40%|▍| 9.68M/24.1M [00:09<00:05, 2.54MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  33%|▎| 6.96M/21.4M [00:09<00:12, 1.20MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  64%|▋| 8.93M/13.9M [00:09<00:02, 2.30MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  45%|▍| 11.0M/24.1M [00:10<00:04, 3.10MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  38%|▍| 8.76M/23.1M [00:10<00:08, 1.77MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  43%|▍| 9.11M/21.4M [00:10<00:05, 2.23MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet: 100%|█| 14.2M/14.2M [00:09<00:00, 3.88MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000007.parquet: 100%|█| 14.2M/14.2M [00:09<00:00, 1.45MB/\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000007.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  47%|▍| 12.3M/26.2M [00:10<00:06, 2.31MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:   1%| | 238k/23.6M [00:01<03:01, 128kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  40%|▍| 9.29M/23.1M [00:10<00:08, 1.65MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  51%|▌| 13.4M/26.2M [00:10<00:04, 2.84MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  49%|▍| 10.5M/21.4M [00:10<00:03, 2.85MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet:  78%|▊| 10.9M/13.9M [00:10<00:01, 2.61MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  51%|▌| 12.2M/24.1M [00:10<00:04, 2.71MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  60%|▌| 15.8M/26.2M [00:10<00:02, 4.43MB/\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000010.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/rsLn5BGebIIw3IlGoKoDqdbDfJY=.8a652e25e7a6d53777834b8e3afe7d373e1ce5cf629dfb473189b87650ad22dd.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  54%|▌| 13.0M/24.1M [00:10<00:03, 3.04MB/\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:   1%| | 300k/23.6M [00:02<02:41, 144kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  57%|▌| 12.2M/21.4M [00:10<00:02, 3.58MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  61%|▌| 13.1M/21.4M [00:10<00:02, 3.56MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000005.parquet: 100%|█| 13.9M/13.9M [00:10<00:00, 1.29MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000005.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  47%|▍| 10.9M/23.1M [00:11<00:06, 1.98MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:   0%|        | 0.00/15.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  61%|▌| 14.1M/23.1M [00:11<00:02, 3.85MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000011.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/JQ2X4gG6nwj5wZMKNyFm_75pPUk=.2d62367f2b1af06d037875d2711b396877ebd276b572658a43cc0e170c9a30fe.incomplete'\n",
      "\n",
      "data/chunk-000/episode_000008.parquet:   6%| | 1.47M/23.6M [00:02<00:29, 740kB/s\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  67%|▋| 17.6M/26.2M [00:11<00:02, 3.17MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:   0%| | 34.8k/23.3M [00:02<31:55, 12.2kB/\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  11%| | 2.49M/23.6M [00:03<00:17, 1.24MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  72%|▋| 16.7M/23.1M [00:12<00:01, 3.60MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:   0%| | 57.4k/23.3M [00:03<20:26, 19.0kB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  56%|▌| 13.4M/24.1M [00:12<00:08, 1.21MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  67%|▋| 14.3M/21.4M [00:11<00:03, 2.18MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  71%|▋| 18.5M/26.2M [00:12<00:02, 2.71MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:   6%| | 1.38M/23.3M [00:03<00:30, 711kB/s\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  13%|▏| 2.95M/23.6M [00:03<00:17, 1.18MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  78%|▊| 18.0M/23.1M [00:12<00:01, 3.80MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  70%|▋| 15.0M/21.4M [00:12<00:02, 2.29MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  60%|▌| 14.5M/24.1M [00:12<00:05, 1.62MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  75%|▊| 19.8M/26.2M [00:12<00:02, 2.78MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  17%|▏| 3.97M/23.6M [00:03<00:11, 1.66MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  72%|▋| 15.5M/21.4M [00:12<00:02, 2.02MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  65%|▋| 15.6M/24.1M [00:12<00:04, 2.03MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  14%|▏| 3.15M/23.3M [00:04<00:14, 1.42MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:   0%|        | 0.00/15.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  20%|▏| 4.74M/23.6M [00:04<00:11, 1.71MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  77%|▊| 16.4M/21.4M [00:12<00:02, 2.18MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  20%|▏| 4.60M/23.3M [00:04<00:09, 2.06MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet:  90%|▉| 23.5M/26.2M [00:13<00:00, 3.96MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet:  89%|▉| 20.6M/23.1M [00:13<00:00, 3.36MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:   0%| | 45.5k/15.9M [00:02<12:14, 21.6kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  22%|▏| 5.18M/23.3M [00:04<00:08, 2.24MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  69%|▋| 16.6M/24.1M [00:13<00:03, 1.96MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet:  84%|▊| 18.0M/21.4M [00:13<00:01, 3.04MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000006.parquet: 100%|█| 23.1M/23.1M [00:13<00:00, 1.70MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000006.parquet\n",
      "\n",
      "data/chunk-000/episode_000008.parquet:  23%|▏| 5.39M/23.6M [00:04<00:11, 1.53MB/\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  74%|▋| 17.8M/24.1M [00:13<00:02, 2.29MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  25%|▎| 5.94M/23.3M [00:05<00:09, 1.89MB/\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  40%|▍| 9.32M/23.6M [00:05<00:03, 3.96MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:   1%| | 92.0k/15.9M [00:02<07:06, 37.1kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000012.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/TPqbhsWoatE4yKHw2We8Qg8XB3E=.5f9ab496a7f53ad978471abfba0b1c96c06392664f115b2d7ece988e08fc5e55.incomplete'\n",
      "\n",
      "data/chunk-000/episode_000008.parquet:  43%|▍| 10.0M/23.6M [00:05<00:03, 4.04MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:   4%| | 624k/15.9M [00:02<00:41, 366kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  28%|▎| 6.51M/23.3M [00:05<00:09, 1.85MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   0%|        | 0.00/22.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  32%|▎| 7.38M/23.3M [00:05<00:06, 2.37MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:   0%| | 10.3k/15.9M [00:01<35:52, 7.39kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:   1%| | 141k/15.9M [00:01<02:13, 118kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  36%|▎| 8.49M/23.3M [00:05<00:05, 2.75MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:  16%|▏| 2.51M/15.9M [00:03<00:10, 1.29MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  56%|▌| 13.2M/23.6M [00:06<00:02, 3.93MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000000.parquet: 100%|█| 21.4M/21.4M [00:14<00:00, 1.46MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000000.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000002.parquet: 100%|█| 26.2M/26.2M [00:14<00:00, 1.76MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000002.parquet\n",
      "Fetching 25 files:   8%|██                       | 2/25 [00:16<03:35,  9.35s/it]\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet:  87%|▊| 21.0M/24.1M [00:14<00:01, 2.42MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:  21%|▏| 3.37M/15.9M [00:03<00:07, 1.64MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  64%|▋| 15.1M/23.6M [00:06<00:01, 4.81MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:   2%| | 315k/15.9M [00:02<01:14, 208kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  39%|▍| 9.08M/23.3M [00:06<00:08, 1.60MB/\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000014.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/A0l4hNmU7lRjoEk64OZsJbvpci0=.91982fda871ffb19f2ca44bf9df9d512bcaa1be7ae97b27a0482750ab494fb42.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:  30%|▎| 4.78M/15.9M [00:04<00:05, 1.86MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000001.parquet: 100%|█| 24.1M/24.1M [00:15<00:00, 1.54MB/\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000001.parquet\n",
      "Fetching 25 files:  12%|███                      | 3/25 [00:17<01:59,  5.41s/it]\n",
      "data/chunk-000/episode_000008.parquet:  77%|▊| 18.2M/23.6M [00:06<00:01, 5.07MB/\u001b[ADownloading 'data/chunk-000/episode_000013.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/P7NzDX_I7S6_SWyl55hM3vUUTys=.093ac39a5e4a88ba7ded1e1b567560526bf9e7be02f03aee56a2f34e0998b25d.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   0%| | 34.3k/22.9M [00:01<17:09, 22.3kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  43%|▍| 9.93M/23.3M [00:07<00:07, 1.68MB/\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000015.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/u8GZgFEljpyIUPL_IlWveQkE4bs=.b5d238fbf7212679effd2f3d3ade21e752be86a78f443242f8858f10e46720a3.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:   6%| | 892k/15.9M [00:03<00:37, 405kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   1%| | 152k/22.9M [00:01<03:26, 110kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000008.parquet:  91%|▉| 21.4M/23.6M [00:07<00:00, 5.69MB/\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   0%|        | 0.00/23.3M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000008.parquet: 100%|█| 23.6M/23.6M [00:07<00:00, 3.16MB/\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000008.parquet\n",
      "Fetching 25 files:  40%|█████████▌              | 10/25 [00:17<00:15,  1.04s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   2%| | 425k/22.9M [00:01<01:01, 368kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:  36%|▎| 5.71M/15.9M [00:04<00:05, 1.78MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   2%| | 555k/22.9M [00:02<00:56, 396kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:  50%|▌| 8.01M/15.9M [00:05<00:02, 2.84MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:  11%| | 1.73M/15.9M [00:03<00:18, 751kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  67%|▋| 15.6M/23.3M [00:07<00:01, 4.61MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:  29%|▎| 4.65M/15.9M [00:03<00:04, 2.57MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:   0%|        | 0.00/15.1M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   4%| | 804k/22.9M [00:02<00:49, 451kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'data/chunk-000/episode_000016.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/rQy_R7aepl1p-x8IAbvG49rmwXI=.5e618465a6b0ef5522350423ca86d944e02ae730464f2ae9cb9b1f9e14dbba01.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:  33%|▎| 5.30M/15.9M [00:04<00:04, 2.64MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:   8%| | 1.79M/22.9M [00:02<00:16, 1.27MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:  40%|▍| 6.37M/15.9M [00:04<00:03, 2.77MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  11%| | 2.51M/22.9M [00:03<00:11, 1.75MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet:  60%|▌| 9.49M/15.9M [00:06<00:02, 2.35MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000016.parquet:   0%|        | 0.00/14.8M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  74%|▋| 17.2M/23.3M [00:08<00:01, 3.12MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  27%|▎| 6.17M/22.9M [00:03<00:02, 5.86MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  40%|▍| 9.08M/22.9M [00:03<00:01, 7.83MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  44%|▍| 10.1M/22.9M [00:03<00:01, 7.20MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   0%| | 40.4k/23.3M [00:01<18:25, 21.1kB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  50%|▌| 11.5M/22.9M [00:03<00:01, 7.26MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet:  66%|▋| 10.5M/15.9M [00:05<00:01, 3.95MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet:  87%|▊| 20.2M/23.3M [00:09<00:00, 3.55MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  63%|▋| 14.4M/22.9M [00:04<00:00, 9.24MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000009.parquet: 100%|█| 23.3M/23.3M [00:09<00:00, 2.42MB/\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000009.parquet\n",
      "Fetching 25 files:  44%|██████████▌             | 11/25 [00:19<00:16,  1.21s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  70%|▋| 16.1M/22.9M [00:04<00:00, 8.93MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   1%| | 175k/23.3M [00:02<04:28, 86.1kB/s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000010.parquet: 100%|█| 15.9M/15.9M [00:07<00:00, 2.13MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000010.parquet\n",
      "Fetching 25 files:  48%|███████████▌            | 12/25 [00:20<00:13,  1.04s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet:  77%|▊| 17.6M/22.9M [00:04<00:00, 8.83MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   1%| | 241k/23.3M [00:02<03:12, 120kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   1%| | 330k/23.3M [00:02<02:03, 186kB/s]\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:   1%| | 117k/15.1M [00:02<04:21, 57.2kB/s\u001b[ADownloading 'data/chunk-000/episode_000017.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/ozqif_TQP2X1DHgMmtW6yBPBUqo=.d76383cf87b1a7617fde054ab234580f70efb05337745cc592610ea1e9622f9b.incomplete'\n",
      "\n",
      "data/chunk-000/episode_000015.parquet:   3%| | 392k/15.1M [00:02<01:09, 213kB/s]\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   2%| | 547k/23.3M [00:03<01:08, 334kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:   0%|        | 0.00/13.0M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   4%| | 880k/23.3M [00:03<00:34, 653kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000012.parquet: 100%|█| 22.9M/22.9M [00:05<00:00, 4.34MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000012.parquet\n",
      "Downloading 'data/chunk-000/episode_000018.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/6biO3olOD5nJEJQBi-EJJYTOyn4=.d45615cc16c302fd2555eed09dca4b39b875f7407dc33fa5f27324ea9524dc28.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:   5%| | 1.06M/23.3M [00:03<00:36, 609kB/s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000011.parquet: 100%|█| 15.9M/15.9M [00:06<00:00, 2.41MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000011.parquet\n",
      "Fetching 25 files:  52%|████████████▍           | 13/25 [00:21<00:12,  1.03s/it]\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  15%|▏| 3.40M/23.3M [00:03<00:06, 3.28MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:   0%|        | 0.00/14.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:   0%|        | 0.00/23.0M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  19%|▏| 4.44M/23.3M [00:03<00:05, 3.76MB/\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:   3%| | 502k/15.1M [00:03<01:24, 173kB/s]\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  24%|▏| 5.58M/23.3M [00:03<00:03, 4.87MB/\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:   5%| | 774k/15.1M [00:03<00:46, 309kB/s]\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  31%|▎| 7.24M/23.3M [00:04<00:02, 6.05MB/\u001b[A\u001b[A\u001b[ADownloading 'meta/episodes.jsonl' to 'demo_data_language/.cache/huggingface/download/meta/Xr2m2iHl-ydc-mHHfOvaRU5pi6o=.ac998d863db5719e11d57ac671b5d130b5f964b7.incomplete'\n",
      "Downloading 'data/chunk-000/episode_000019.parquet' to 'demo_data_language/.cache/huggingface/download/data/chunk-000/DicwzzxqerJmAskDiOn4wMk3ozw=.b4353bc1c0f3c70bb9a40ee36cd5ca3b21c2fd04df86e72dbe88318758534853.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  35%|▎| 8.09M/23.3M [00:04<00:03, 4.47MB/\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:   6%| | 968k/15.1M [00:03<00:39, 361kB/s]\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:  19%|▏| 2.80M/15.1M [00:04<00:07, 1.74MB/\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  41%|▍| 9.57M/23.3M [00:04<00:02, 5.16MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "episodes.jsonl: 1.66kB [00:00, 13.2MB/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/meta/episodes.jsonl\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  53%|▌| 12.4M/23.3M [00:04<00:01, 8.58MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:   1%| | 115k/13.0M [00:02<03:57, 54.5kB/s\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:  22%|▏| 3.31M/15.1M [00:05<00:13, 904kB/s\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:   2%| | 266k/13.0M [00:03<02:30, 84.7kB/s\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:  27%|▎| 4.12M/15.1M [00:05<00:09, 1.10MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:   0%| | 64.8k/23.0M [00:02<16:07, 23.8kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  63%|▋| 14.7M/23.3M [00:06<00:03, 2.84MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:   2%| | 311k/14.4M [00:02<02:10, 108kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:  12%| | 1.61M/13.0M [00:03<00:15, 748kB/s\u001b[A\u001b[ADownloading 'meta/episodes_stats.jsonl' to 'demo_data_language/.cache/huggingface/download/meta/OSV6LZWLsNGAwnFDfYELN9vNGMw=.898b2255b32186b3c09e7bf597a7a1b739c42e69.incomplete'\n",
      "\n",
      "data/chunk-000/episode_000015.parquet:  45%|▍| 6.81M/15.1M [00:05<00:03, 2.72MB/\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:  23%|▏| 2.95M/13.0M [00:03<00:06, 1.58MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:   4%| | 594k/14.4M [00:03<00:58, 234kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:   3%| | 750k/23.0M [00:02<01:03, 352kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  69%|▋| 16.2M/23.3M [00:06<00:02, 3.44MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "episodes_stats.jsonl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:  63%|▋| 9.45M/15.1M [00:06<00:01, 3.30MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:   0%|        | 0.00/14.7M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:  11%| | 1.62M/14.4M [00:04<00:26, 489kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet:  71%|▋| 10.7M/15.1M [00:07<00:01, 2.63MB/\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "episodes_stats.jsonl: 60.6kB [00:00, 70.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/meta/episodes_stats.jsonl\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:  37%|▎| 4.81M/13.0M [00:05<00:06, 1.35MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:   6%| | 1.45M/23.0M [00:04<00:54, 394kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:  46%|▍| 6.04M/13.0M [00:05<00:03, 1.84MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:   8%| | 1.77M/23.0M [00:04<00:41, 515kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  10%| | 2.19M/23.0M [00:04<00:28, 732kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:  17%|▏| 2.48M/14.4M [00:04<00:16, 732kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:  23%|▏| 3.32M/14.4M [00:05<00:11, 988kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:  56%|▌| 7.34M/13.0M [00:05<00:02, 2.02MB/\u001b[A\u001b[ADownloading 'meta/info.json' to 'demo_data_language/.cache/huggingface/download/meta/c-Q9HGFI0JpMTOZ5pylhXwaYu2U=.5966d59e3fac6302b84d5ca141fab8a4b24eef43.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  13%|▏| 2.93M/23.0M [00:05<00:21, 917kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet:  89%|▉| 20.7M/23.3M [00:09<00:01, 2.36MB/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:   0%| | 10.3k/14.7M [00:02<59:04, 4.14kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "info.json: 2.34kB [00:00, 18.2MB/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/meta/info.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  26%|▎| 5.98M/23.0M [00:06<00:09, 1.77MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  29%|▎| 6.64M/23.0M [00:06<00:08, 1.99MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "data/chunk-000/episode_000017.parquet:  80%|▊| 10.5M/13.0M [00:07<00:01, 2.07MB/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:  66%|▋| 9.49M/14.4M [00:06<00:01, 2.54MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:   2%| | 283k/14.7M [00:02<01:50, 130kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000014.parquet: 100%|█| 23.3M/23.3M [00:10<00:00, 2.21MB/\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000014.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  59%|▌| 13.7M/23.0M [00:06<00:01, 6.58MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:   6%| | 897k/14.7M [00:03<00:27, 496kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "data/chunk-000/episode_000015.parquet: 100%|█| 15.1M/15.1M [00:10<00:00, 1.51MB/\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000015.parquet\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000017.parquet: 100%|█| 13.0M/13.0M [00:07<00:00, 1.67MB/\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000017.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:  19%|▏| 2.76M/14.7M [00:03<00:08, 1.44MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'meta/tasks.jsonl' to 'demo_data_language/.cache/huggingface/download/meta/NzWDcOlnTQhMC9idVZndPYjQOjQ=.63cd9a9ff9456c708f27100ed34845111980ac08.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  69%|▋| 15.8M/23.0M [00:07<00:01, 4.97MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "tasks.jsonl: 100%|█████████████████████████████| 123/123 [00:00<00:00, 1.51MB/s]\u001b[A\n",
      "Download complete. Moving file to demo_data_language/meta/tasks.jsonl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet:  82%|▊| 11.8M/14.4M [00:08<00:01, 2.25MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:  26%|▎| 3.77M/14.7M [00:04<00:08, 1.33MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000013.parquet: 100%|█| 14.4M/14.4M [00:08<00:00, 1.73MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000013.parquet\n",
      "Fetching 25 files:  60%|██████████████▍         | 15/25 [00:29<00:21,  2.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000018.parquet:  75%|▊| 17.3M/23.0M [00:08<00:01, 3.94MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet:  87%|▊| 12.9M/14.7M [00:04<00:00, 7.11MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000019.parquet: 100%|█| 14.7M/14.7M [00:04<00:00, 3.17MB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000019.parquet\n",
      "data/chunk-000/episode_000018.parquet: 100%|█| 23.0M/23.0M [00:08<00:00, 2.72MB/\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000018.parquet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data/chunk-000/episode_000016.parquet: 100%|█| 14.8M/14.8M [00:12<00:00, 1.21MB/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to demo_data_language/data/chunk-000/episode_000016.parquet\n",
      "Fetching 25 files: 100%|████████████████████████| 25/25 [00:31<00:00,  1.24s/it]\n",
      "/home/wzy/lerobot-mujoco/demo_data_language\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download Jeongeun/omy_pnp_language --repo-type dataset --local-dir ./demo_data_language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246fa3e",
   "metadata": {},
   "source": [
    "## Step 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ca989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🚀 Training Started | 训练已开始\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "✅ Training Completed! | 训练完成！\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!python train_model.py --config_path smolvla_omy.yaml\n",
    "from train_with_monitor_cell import train_with_monitor\n",
    "train_with_monitor(\"smolvla_omy.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20673462",
   "metadata": {},
   "source": [
    "## Step 3. Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07386e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import numpy as np\n",
    "from lerobot.common.datasets.utils import write_json, serialize_dict\n",
    "from lerobot.common.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "from lerobot.common.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.common.datasets.factory import resolve_delta_timestamps\n",
    "from lerobot.common.datasets.utils import dataset_to_policy_features\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b1f651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "381de80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./demo_data_language')\n",
    "except:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./omy_pnp_language')\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
    "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
    "# Temporal ensemble to make smoother trajectory predictions\n",
    "cfg = SmolVLAConfig(input_features=input_features, output_features=output_features, chunk_size= 5, n_action_steps=5)\n",
    "delta_timestamps = resolve_delta_timestamps(cfg, dataset_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e38030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmolVLAPolicy(\n",
       "  (normalize_inputs): Normalize(\n",
       "    (buffer_observation_state): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (normalize_targets): Normalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (unnormalize_outputs): Unnormalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (model): VLAFlowMatching(\n",
       "    (vlm_with_expert): SmolVLMWithExpertModel(\n",
       "      (vlm): SmolVLMForConditionalGeneration(\n",
       "        (model): SmolVLMModel(\n",
       "          (vision_model): SmolVLMVisionTransformer(\n",
       "            (embeddings): SmolVLMVisionEmbeddings(\n",
       "              (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
       "              (position_embedding): Embedding(1024, 768)\n",
       "            )\n",
       "            (encoder): SmolVLMEncoder(\n",
       "              (layers): ModuleList(\n",
       "                (0-11): 12 x SmolVLMEncoderLayer(\n",
       "                  (self_attn): SmolVLMVisionAttention(\n",
       "                    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                  (mlp): SmolVLMVisionMLP(\n",
       "                    (activation_fn): PytorchGELUTanh()\n",
       "                    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (connector): SmolVLMConnector(\n",
       "            (modality_projection): SmolVLMSimpleMLP(\n",
       "              (proj): Linear(in_features=12288, out_features=960, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (text_model): LlamaModel(\n",
       "            (embed_tokens): Embedding(49280, 960, padding_idx=2)\n",
       "            (layers): ModuleList(\n",
       "              (0-15): 16 x LlamaDecoderLayer(\n",
       "                (self_attn): LlamaAttention(\n",
       "                  (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                  (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                )\n",
       "                (mlp): LlamaMLP(\n",
       "                  (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "                  (act_fn): SiLU()\n",
       "                )\n",
       "                (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "                (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "              )\n",
       "            )\n",
       "            (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "        )\n",
       "        (lm_head): Linear(in_features=960, out_features=49280, bias=False)\n",
       "      )\n",
       "      (lm_expert): LlamaModel(\n",
       "        (embed_tokens): None\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (2): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (3): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (4): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (5): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (6): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (7): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (8): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (9): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (10): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (11): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (12): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (13): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (14): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (15): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (state_proj): Linear(in_features=32, out_features=960, bias=True)\n",
       "    (action_in_proj): Linear(in_features=32, out_features=720, bias=True)\n",
       "    (action_out_proj): Linear(in_features=720, out_features=32, bias=True)\n",
       "    (action_time_mlp_in): Linear(in_features=1440, out_features=720, bias=True)\n",
       "    (action_time_mlp_out): Linear(in_features=720, out_features=720, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now instantiate our policy with this config and the dataset stats.\n",
    "policy = SmolVLAPolicy.from_pretrained('ckpt/smolvla_omy_20251103_140619/checkpoints/last/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85ebd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      " n_qpos:[31] n_qvel:[28] n_qacc:[28] n_ctrl:[10]\n",
      " integrator:[IMPLICITFAST]\n",
      "\n",
      "n_body:[23]\n",
      " [0/23] [world] mass:[0.00]kg\n",
      " [1/23] [front_object_table] mass:[1.00]kg\n",
      " [2/23] [camera] mass:[0.00]kg\n",
      " [3/23] [camera2] mass:[0.00]kg\n",
      " [4/23] [camera3] mass:[0.00]kg\n",
      " [5/23] [link1] mass:[2.06]kg\n",
      " [6/23] [link2] mass:[3.68]kg\n",
      " [7/23] [link3] mass:[2.39]kg\n",
      " [8/23] [link4] mass:[1.40]kg\n",
      " [9/23] [link5] mass:[1.40]kg\n",
      " [10/23] [link6] mass:[0.65]kg\n",
      " [11/23] [camera_center] mass:[0.00]kg\n",
      " [12/23] [tcp_link] mass:[0.32]kg\n",
      " [13/23] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/23] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/23] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/23] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/23] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/23] [object_mug_5] mass:[0.08]kg\n",
      " [19/23] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/23] [object_plate_11] mass:[0.10]kg\n",
      " [21/23] [body_obj_mug_6] mass:[0.00]kg\n",
      " [22/23] [object_mug_6] mass:[0.08]kg\n",
      "body_total_mass:[13.35]kg\n",
      "\n",
      "n_geom:[116]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_mesh:[112]\n",
      "mesh_names:['base_unit', 'link1', 'link2', 'link3', 'link4', 'link5', 'link6', 'flange', 'base', 'r1', 'r2', 'l1', 'l2', 'mug_5_normalized_0_vis', 'mug_5_normalized_collision_22._coll', 'mug_5_normalized_collision_23._coll', 'mug_5_normalized_collision_21._coll', 'mug_5_normalized_collision_20._coll', 'mug_5_normalized_collision_24._coll', 'mug_5_normalized_collision_30._coll', 'mug_5_normalized_collision_18._coll', 'mug_5_normalized_collision_19._coll', 'mug_5_normalized_collision_31._coll', 'mug_5_normalized_collision_25._coll', 'mug_5_normalized_collision_27._coll', 'mug_5_normalized_collision_26._coll', 'mug_5_normalized_collision_9._coll', 'mug_5_normalized_collision_8._coll', 'mug_5_normalized_collision_6._coll', 'mug_5_normalized_collision_7._coll', 'mug_5_normalized_collision_5._coll', 'mug_5_normalized_collision_4._coll', 'mug_5_normalized_collision_0._coll', 'mug_5_normalized_collision_1._coll', 'mug_5_normalized_collision_3._coll', 'mug_5_normalized_collision_2._coll', 'mug_5_normalized_collision_17._coll', 'mug_5_normalized_collision_16._coll', 'mug_5_normalized_collision_28._coll', 'mug_5_normalized_collision_14._coll', 'mug_5_normalized_collision_15._coll', 'mug_5_normalized_collision_29._coll', 'mug_5_normalized_collision_11._coll', 'mug_5_normalized_collision_10._coll', 'mug_5_normalized_collision_12._coll', 'mug_5_normalized_collision_13._coll', 'plate_11_normalized_0_vis', 'plate_11_normalized_collision_22._coll', 'plate_11_normalized_collision_23._coll', 'plate_11_normalized_collision_21._coll', 'plate_11_normalized_collision_20._coll', 'plate_11_normalized_collision_24._coll', 'plate_11_normalized_collision_30._coll', 'plate_11_normalized_collision_18._coll', 'plate_11_normalized_collision_19._coll', 'plate_11_normalized_collision_31._coll', 'plate_11_normalized_collision_25._coll', 'plate_11_normalized_collision_27._coll', 'plate_11_normalized_collision_26._coll', 'plate_11_normalized_collision_9._coll', 'plate_11_normalized_collision_8._coll', 'plate_11_normalized_collision_6._coll', 'plate_11_normalized_collision_7._coll', 'plate_11_normalized_collision_5._coll', 'plate_11_normalized_collision_4._coll', 'plate_11_normalized_collision_0._coll', 'plate_11_normalized_collision_1._coll', 'plate_11_normalized_collision_3._coll', 'plate_11_normalized_collision_2._coll', 'plate_11_normalized_collision_17._coll', 'plate_11_normalized_collision_16._coll', 'plate_11_normalized_collision_28._coll', 'plate_11_normalized_collision_14._coll', 'plate_11_normalized_collision_15._coll', 'plate_11_normalized_collision_29._coll', 'plate_11_normalized_collision_11._coll', 'plate_11_normalized_collision_10._coll', 'plate_11_normalized_collision_12._coll', 'plate_11_normalized_collision_13._coll', 'mug_6_normalized_0_vis', 'mug_6_normalized_collision_22._coll', 'mug_6_normalized_collision_23._coll', 'mug_6_normalized_collision_21._coll', 'mug_6_normalized_collision_20._coll', 'mug_6_normalized_collision_24._coll', 'mug_6_normalized_collision_30._coll', 'mug_6_normalized_collision_18._coll', 'mug_6_normalized_collision_19._coll', 'mug_6_normalized_collision_31._coll', 'mug_6_normalized_collision_25._coll', 'mug_6_normalized_collision_27._coll', 'mug_6_normalized_collision_26._coll', 'mug_6_normalized_collision_9._coll', 'mug_6_normalized_collision_8._coll', 'mug_6_normalized_collision_6._coll', 'mug_6_normalized_collision_7._coll', 'mug_6_normalized_collision_5._coll', 'mug_6_normalized_collision_4._coll', 'mug_6_normalized_collision_0._coll', 'mug_6_normalized_collision_1._coll', 'mug_6_normalized_collision_3._coll', 'mug_6_normalized_collision_2._coll', 'mug_6_normalized_collision_17._coll', 'mug_6_normalized_collision_16._coll', 'mug_6_normalized_collision_28._coll', 'mug_6_normalized_collision_14._coll', 'mug_6_normalized_collision_15._coll', 'mug_6_normalized_collision_29._coll', 'mug_6_normalized_collision_11._coll', 'mug_6_normalized_collision_10._coll', 'mug_6_normalized_collision_12._coll', 'mug_6_normalized_collision_13._coll']\n",
      "\n",
      "n_joint:[13]\n",
      " [0/13] [joint1] axis:[0. 0. 1.]\n",
      " [1/13] [joint2] axis:[0. 1. 0.]\n",
      " [2/13] [joint3] axis:[0. 1. 0.]\n",
      " [3/13] [joint4] axis:[0. 1. 0.]\n",
      " [4/13] [joint5] axis:[0. 0. 1.]\n",
      " [5/13] [joint6] axis:[0. 1. 0.]\n",
      " [6/13] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/13] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/13] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/13] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/13] [None] axis:[0. 0. 1.]\n",
      " [11/13] [None] axis:[0. 0. 1.]\n",
      " [12/13] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[28] (=number of rows of Jacobian)\n",
      " [0/28] [None] attached joint:[joint1] body:[link1]\n",
      " [1/28] [None] attached joint:[joint2] body:[link2]\n",
      " [2/28] [None] attached joint:[joint3] body:[link3]\n",
      " [3/28] [None] attached joint:[joint4] body:[link4]\n",
      " [4/28] [None] attached joint:[joint5] body:[link5]\n",
      " [5/28] [None] attached joint:[joint6] body:[link6]\n",
      " [6/28] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/28] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/28] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/28] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [22/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [23/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [24/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [25/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [26/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [27/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      "\n",
      "Free joint information. n_free_joint:[3]\n",
      " [0/3] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/3] [None] body_name_attached:[body_obj_plate_11]\n",
      " [2/3] [None] body_name_attached:[body_obj_mug_6]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[9]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11', 'bottom_site_mug_6', 'top_site_mug_6', 'horizontal_radius_site_mug_6']\n",
      "-----------------------------------------------------------------------------\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "from mujoco_env.y_env2 import SimpleEnv2\n",
    "xml_path = './asset/example_scene_y2.xml'\n",
    "PnPEnv = SimpleEnv2(xml_path, action_type='joint_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db761f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Approach 1: Using torchvision.transforms\n",
    "def get_default_transform(image_size: int = 224):\n",
    "    \"\"\"\n",
    "    Returns a torchvision transform that:\n",
    "     Converts to a FloatTensor and scales pixel values [0,255] -> [0.0,1.0]\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL [0–255] -> FloatTensor [0.0–1.0], shape C×H×W\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a7d54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 36\u001b[0m\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation.state\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor([state])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation.image\u001b[39m\u001b[38;5;124m'\u001b[39m: image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation.wrist_image\u001b[39m\u001b[38;5;124m'\u001b[39m: wrist_image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: [PnPEnv\u001b[38;5;241m.\u001b[39minstruction],\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Select an action\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m action \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m,:\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Take a step in the environment\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:296\u001b[0m, in \u001b[0;36mSmolVLAPolicy.select_action\u001b[0;34m(self, batch, noise)\u001b[0m\n\u001b[1;32m    293\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_state(batch)\n\u001b[1;32m    294\u001b[0m lang_tokens, lang_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_language(batch)\n\u001b[0;32m--> 296\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Unpad actions\u001b[39;00m\n\u001b[1;32m    300\u001b[0m original_action_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maction_feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:757\u001b[0m, in \u001b[0;36mVLAFlowMatching.sample_actions\u001b[0;34m(self, images, img_masks, lang_tokens, lang_masks, state, noise)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mdt \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    756\u001b[0m     expanded_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mexpand(bsize)\n\u001b[0;32m--> 757\u001b[0m     v_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_pad_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpanded_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# Euler step\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     x_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dt \u001b[38;5;241m*\u001b[39m v_t\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:789\u001b[0m, in \u001b[0;36mVLAFlowMatching.denoise_step\u001b[0;34m(self, prefix_pad_masks, past_key_values, x_t, timestep)\u001b[0m\n\u001b[1;32m    786\u001b[0m prefix_offsets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(prefix_pad_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    787\u001b[0m position_ids \u001b[38;5;241m=\u001b[39m prefix_offsets \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumsum(suffix_pad_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 789\u001b[0m outputs_embeds, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvlm_with_expert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_att_2d_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix_embs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_kv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m suffix_out \u001b[38;5;241m=\u001b[39m outputs_embeds[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    798\u001b[0m suffix_out \u001b[38;5;241m=\u001b[39m suffix_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mchunk_size :]\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/smolvlm_with_expert.py:445\u001b[0m, in \u001b[0;36mSmolVLMWithExpertModel.forward\u001b[0;34m(self, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, fill_kv_cache)\u001b[0m\n\u001b[1;32m    432\u001b[0m     att_outputs, past_key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_attn_layer(\n\u001b[1;32m    433\u001b[0m         model_layers,\n\u001b[1;32m    434\u001b[0m         inputs_embeds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m     att_outputs, past_key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_cross_attn_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_kv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m outputs_embeds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/smolvlm_with_expert.py:373\u001b[0m, in \u001b[0;36mSmolVLMWithExpertModel.forward_cross_attn_layer\u001b[0;34m(self, model_layers, inputs_embeds, layer_idx, position_ids, attention_mask, batch_size, head_dim, use_cache, fill_kv_cache, past_key_values)\u001b[0m\n\u001b[1;32m    366\u001b[0m expert_position_id \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    367\u001b[0m     expert_position_id \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(expert_position_id, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    368\u001b[0m )  \u001b[38;5;66;03m# start from 0\u001b[39;00m\n\u001b[1;32m    369\u001b[0m expert_attention_mask \u001b[38;5;241m=\u001b[39m attention_mask[\n\u001b[1;32m    370\u001b[0m     :, \u001b[38;5;241m-\u001b[39minputs_embeds[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] :, : expert_key_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] :\n\u001b[1;32m    371\u001b[0m ]  \u001b[38;5;66;03m# take into account kv\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m expert_query_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpert_query_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_position_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m att_output \u001b[38;5;241m=\u001b[39m attention_interface(\n\u001b[1;32m    376\u001b[0m     expert_attention_mask,\n\u001b[1;32m    377\u001b[0m     batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m     expert_value_states,\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    383\u001b[0m att_outputs\u001b[38;5;241m.\u001b[39mappend(att_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "PnPEnv.reset(seed=0)\n",
    "policy.reset()\n",
    "policy.eval()\n",
    "save_image = True\n",
    "IMG_TRANSFORM = get_default_transform()\n",
    "while PnPEnv.env.is_viewer_alive():\n",
    "    PnPEnv.step_env()\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        # Check if the task is completed\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            # Reset the environment and action queue\n",
    "            policy.reset()\n",
    "            PnPEnv.reset()\n",
    "            step = 0\n",
    "            save_image = False\n",
    "        # Get the current state of the environment\n",
    "        state = PnPEnv.get_joint_state()[:6]\n",
    "        # Get the current image from the environment\n",
    "        image, wirst_image = PnPEnv.grab_image()\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((256, 256))\n",
    "        image = IMG_TRANSFORM(image)\n",
    "        wrist_image = Image.fromarray(wirst_image)\n",
    "        wrist_image = wrist_image.resize((256, 256))\n",
    "        wrist_image = IMG_TRANSFORM(wrist_image)\n",
    "        data = {\n",
    "            'observation.state': torch.tensor([state]).to(device),\n",
    "            'observation.image': image.unsqueeze(0).to(device),\n",
    "            'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
    "            'task': [PnPEnv.instruction],\n",
    "        }\n",
    "        # Select an action\n",
    "        action = policy.select_action(data)\n",
    "        action = action[0,:7].cpu().detach().numpy()\n",
    "        # Take a step in the environment\n",
    "        _ = PnPEnv.step(action)\n",
    "        PnPEnv.render()\n",
    "        step += 1\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b593df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.20G/1.20G [02:26<00:00, 8.19MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Jeongeun/omy_pnp_smolvla/commit/738e2cb9235562d58842ceb8a9469ae21278bb53', commit_message='Add trained policy for PnP task', commit_description='', oid='738e2cb9235562d58842ceb8a9469ae21278bb53', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Jeongeun/omy_pnp_smolvla', endpoint='https://huggingface.co', repo_type='model', repo_id='Jeongeun/omy_pnp_smolvla'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# policy.push_to_hub(\n",
    "#     repo_id='Jeongeun/omy_pnp_smolvla',\n",
    "#     commit_message='Add trained policy for PnP task',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}