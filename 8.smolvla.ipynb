{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7082c8b7",
   "metadata": {},
   "source": [
    "# Deploy Trained Smolvla Policy\n",
    "\n",
    "<img src=\"./media/rollout3.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Deploy trained policy in simulation.\n",
    "# ========================================\n",
    "# 8.smolvla.ipynb - SmolVLA策略部署与测试\n",
    "# ========================================\n",
    "# 功能：加载训练好的SmolVLA模型，并在MuJoCo仿真环境中进行实际部署测试\n",
    "# SmolVLA = Small Vision-Language-Action Model（小型视觉-语言-动作模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f883bd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DISPLAY设置为: :0\n",
      "✓ MUJOCO_GL: egl (GPU硬件加速)\n",
      "✓ NVIDIA GPU优化已启用\n",
      "✓ OpenGL性能优化已启用\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - 设置环境变量（必须第一个运行）\n",
    "import os\n",
    "\n",
    "# 1. 设置DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"✓ DISPLAY设置为: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. 强制使用GPU渲染（关键！）\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGL后端GPU加速\n",
    "print(f\"✓ MUJOCO_GL: egl (GPU硬件加速)\")\n",
    "\n",
    "# 3. NVIDIA GPU优化\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # 关闭垂直同步\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # 减少CPU等待\n",
    "print(\"✓ NVIDIA GPU优化已启用\")\n",
    "\n",
    "# 4. OpenGL性能优化\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # 关闭抗锯齿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # 关闭各向异性过滤\n",
    "print(\"✓ OpenGL性能优化已启用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab95e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.50.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (4.50.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (2025.10.23)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (0.21.4)\n",
      "Requirement already satisfied: requests in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (6.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (2.2.6)\n",
      "Requirement already satisfied: filelock in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from transformers==4.50.3) (3.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (4.15.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (2025.10.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->transformers==4.50.3) (3.11)\n",
      "Requirement already satisfied: num2words in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (0.5.14)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from num2words) (0.6.2)\n",
      "Requirement already satisfied: accelerate in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: psutil in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (7.1.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: pyyaml in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: filelock in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: networkx in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.50.3\n",
    "!pip install num2words\n",
    "!pip install accelerate\n",
    "!pip install safetensors>=0.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c036d1f",
   "metadata": {},
   "source": [
    "### [Optional] Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c3d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: 目标路径 'omy_pnp_language' 已经存在，并且不是一个空目录。\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "If you want to use the collected dataset, please download it from Hugging Face.\n",
    "'''\n",
    "!git clone https://huggingface.co/datasets/Jeongeun/omy_pnp_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246fa3e",
   "metadata": {},
   "source": [
    "## Step 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2025-11-03 13:28:43 in_model.py:111 {'batch_size': 32,\n",
      " 'dataset': {'episodes': None,\n",
      "             'image_transforms': {'enable': False,\n",
      "                                  'max_num_transforms': 3,\n",
      "                                  'random_order': False,\n",
      "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
      "                                                                                   1.2]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
      "                                                                               1.2]},\n",
      "                                                       'type': 'ColorJitter',\n",
      "                                                       'weight': 1.0},\n",
      "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
      "                                                                     0.05]},\n",
      "                                                  'type': 'ColorJitter',\n",
      "                                                  'weight': 1.0},\n",
      "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
      "                                                                                   1.5]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
      "                                                                                 1.5]},\n",
      "                                                        'type': 'SharpnessJitter',\n",
      "                                                        'weight': 1.0}}},\n",
      "             'repo_id': 'omy_pnp_language',\n",
      "             'revision': None,\n",
      "             'root': './demo_data_language',\n",
      "             'use_imagenet_stats': True,\n",
      "             'video_backend': 'torchcodec'},\n",
      " 'env': None,\n",
      " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
      " 'eval_freq': -1,\n",
      " 'job_name': 'smolvla_omy',\n",
      " 'log_freq': 50,\n",
      " 'num_workers': 16,\n",
      " 'optimizer': {'betas': [0.9, 0.95],\n",
      "               'eps': 1e-08,\n",
      "               'grad_clip_norm': 10,\n",
      "               'lr': 0.0001,\n",
      "               'type': 'adamw',\n",
      "               'weight_decay': 1e-10},\n",
      " 'output_dir': 'ckpt/smolvla_omy',\n",
      " 'policy': {'adapt_to_pi_aloha': False,\n",
      "            'add_image_special_tokens': False,\n",
      "            'attention_mode': 'cross_attn',\n",
      "            'chunk_size': 5,\n",
      "            'device': 'cuda',\n",
      "            'empty_cameras': 0,\n",
      "            'expert_width_multiplier': 0.75,\n",
      "            'freeze_vision_encoder': True,\n",
      "            'input_features': {},\n",
      "            'load_vlm_weights': False,\n",
      "            'max_action_dim': 32,\n",
      "            'max_period': 4.0,\n",
      "            'max_state_dim': 32,\n",
      "            'min_period': 0.004,\n",
      "            'n_action_steps': 5,\n",
      "            'n_obs_steps': 1,\n",
      "            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>},\n",
      "            'num_expert_layers': -1,\n",
      "            'num_steps': 10,\n",
      "            'num_vlm_layers': 16,\n",
      "            'optimizer_betas': [0.9, 0.95],\n",
      "            'optimizer_eps': 1e-08,\n",
      "            'optimizer_grad_clip_norm': 10,\n",
      "            'optimizer_lr': 0.0001,\n",
      "            'optimizer_weight_decay': 1e-10,\n",
      "            'output_features': {},\n",
      "            'pad_language_to': 'longest',\n",
      "            'prefix_length': -1,\n",
      "            'resize_imgs_with_padding': [512, 512],\n",
      "            'scheduler_decay_lr': 2.5e-06,\n",
      "            'scheduler_decay_steps': 30000,\n",
      "            'scheduler_warmup_steps': 1000,\n",
      "            'self_attn_every_n_layers': 2,\n",
      "            'tokenizer_max_length': 48,\n",
      "            'train_expert_only': True,\n",
      "            'train_state_proj': True,\n",
      "            'type': 'smolvla',\n",
      "            'use_amp': False,\n",
      "            'use_cache': True,\n",
      "            'use_delta_joint_actions_aloha': False,\n",
      "            'vlm_model_name': 'HuggingFaceTB/SmolVLM2-500M-Video-Instruct'},\n",
      " 'resume': False,\n",
      " 'save_checkpoint': True,\n",
      " 'save_freq': 10000,\n",
      " 'scheduler': {'decay_lr': 2.5e-06,\n",
      "               'num_decay_steps': 30000,\n",
      "               'num_warmup_steps': 1000,\n",
      "               'peak_lr': 0.0001,\n",
      "               'type': 'cosine_decay_with_warmup'},\n",
      " 'seed': 42,\n",
      " 'steps': 2000,\n",
      " 'use_policy_training_preset': True,\n",
      " 'wandb': {'disable_artifact': True,\n",
      "           'enable': True,\n",
      "           'entity': None,\n",
      "           'mode': None,\n",
      "           'notes': None,\n",
      "           'project': 'smolvla_omy',\n",
      "           'run_id': None}}\n",
      "\u001b[1m\u001b[34mLogs will be synced with wandb.\u001b[0m\n",
      "INFO 2025-11-03 13:28:48 ndb_utils.py:96 Track this run --> \u001b[1m\u001b[33mhttps://wandb.ai/qwzy-wzy/smolvla_omy/runs/j6koaoda\u001b[0m\n",
      "INFO 2025-11-03 13:28:48 in_model.py:127 Creating dataset\n",
      "INFO 2025-11-03 13:28:49 in_model.py:138 Creating policy\n",
      "Reducing the number of VLM layers to 16 ...\n",
      "INFO 2025-11-03 13:29:13 in_model.py:148 Creating optimizer and scheduler\n",
      "INFO 2025-11-03 13:29:13 in_model.py:160 \u001b[1m\u001b[33mOutput dir:\u001b[0m ckpt/smolvla_omy\n",
      "INFO 2025-11-03 13:29:13 in_model.py:163 cfg.steps=2000 (2K)\n",
      "INFO 2025-11-03 13:29:13 in_model.py:164 dataset.num_frames=6931 (7K)\n",
      "INFO 2025-11-03 13:29:13 in_model.py:165 dataset.num_episodes=16\n",
      "INFO 2025-11-03 13:29:13 in_model.py:166 num_learnable_params=99880992 (100M)\n",
      "INFO 2025-11-03 13:29:13 in_model.py:167 num_total_params=450046216 (450M)\n",
      "INFO 2025-11-03 13:29:13 in_model.py:206 Start offline training on a fixed dataset\n",
      "INFO 2025-11-03 13:31:00 in_model.py:236 step:50 smpl:2K ep:4 epch:0.23 loss:0.259 grdn:2.088 lr:2.6e-06 updt_s:2.107 data_s:0.026\n",
      "WARNING 2025-11-03 13:31:00 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:31:00 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:32:44 in_model.py:236 step:100 smpl:3K ep:7 epch:0.46 loss:0.197 grdn:1.357 lr:7.6e-06 updt_s:2.080 data_s:0.000\n",
      "WARNING 2025-11-03 13:32:44 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:32:44 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:34:28 in_model.py:236 step:150 smpl:5K ep:11 epch:0.69 loss:0.124 grdn:0.957 lr:1.3e-05 updt_s:2.080 data_s:0.000\n",
      "WARNING 2025-11-03 13:34:28 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:34:28 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:36:12 in_model.py:236 step:200 smpl:6K ep:15 epch:0.92 loss:0.093 grdn:0.701 lr:1.8e-05 updt_s:2.080 data_s:0.000\n",
      "WARNING 2025-11-03 13:36:12 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:36:12 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-11-03 13:37:57 in_model.py:236 step:250 smpl:8K ep:18 epch:1.15 loss:0.074 grdn:0.649 lr:2.3e-05 updt_s:2.067 data_s:0.026\n",
      "WARNING 2025-11-03 13:37:57 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:37:57 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:39:41 in_model.py:236 step:300 smpl:10K ep:22 epch:1.39 loss:0.065 grdn:0.675 lr:2.8e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:39:41 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:39:41 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:41:25 in_model.py:236 step:350 smpl:11K ep:26 epch:1.62 loss:0.058 grdn:0.694 lr:3.3e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:41:25 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:41:25 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:43:09 in_model.py:236 step:400 smpl:13K ep:30 epch:1.85 loss:0.049 grdn:0.752 lr:3.8e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:43:09 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:43:09 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-11-03 13:44:53 in_model.py:236 step:450 smpl:14K ep:33 epch:2.08 loss:0.043 grdn:0.724 lr:4.3e-05 updt_s:2.061 data_s:0.030\n",
      "WARNING 2025-11-03 13:44:53 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:44:53 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:46:37 in_model.py:236 step:500 smpl:16K ep:37 epch:2.31 loss:0.034 grdn:0.706 lr:4.8e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:46:37 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:46:37 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:48:21 in_model.py:236 step:550 smpl:18K ep:41 epch:2.54 loss:0.029 grdn:0.735 lr:5.3e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:48:21 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:48:21 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:50:05 in_model.py:236 step:600 smpl:19K ep:44 epch:2.77 loss:0.034 grdn:0.857 lr:5.8e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:50:05 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:50:05 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:51:49 in_model.py:236 step:650 smpl:21K ep:48 epch:3.00 loss:0.035 grdn:0.822 lr:6.3e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:51:49 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:51:49 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-11-03 13:53:34 in_model.py:236 step:700 smpl:22K ep:52 epch:3.23 loss:0.031 grdn:0.779 lr:6.8e-05 updt_s:2.060 data_s:0.034\n",
      "WARNING 2025-11-03 13:53:34 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:53:34 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:55:18 in_model.py:236 step:750 smpl:24K ep:55 epch:3.46 loss:0.032 grdn:0.791 lr:7.3e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:55:18 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:55:18 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:57:02 in_model.py:236 step:800 smpl:26K ep:59 epch:3.69 loss:0.033 grdn:0.793 lr:7.8e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:57:02 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:57:02 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "INFO 2025-11-03 13:58:45 in_model.py:236 step:850 smpl:27K ep:63 epch:3.92 loss:0.032 grdn:0.759 lr:8.3e-05 updt_s:2.077 data_s:0.000\n",
      "WARNING 2025-11-03 13:58:46 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 13:58:46 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-11-03 14:00:30 in_model.py:236 step:900 smpl:29K ep:66 epch:4.16 loss:0.040 grdn:0.951 lr:8.8e-05 updt_s:2.060 data_s:0.025\n",
      "WARNING 2025-11-03 14:00:30 db_utils.py:117 WandB logging of key \"losses_after_forward\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "WARNING 2025-11-03 14:00:30 db_utils.py:117 WandB logging of key \"losses_after_rm_padding\" was ignored as its type \"<class 'torch.Tensor'>\" is not handled by this wrapper.\n",
      "Exception in thread Thread-6 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "    WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "    WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised e^C\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n",
      "WARNING 2025-11-03 14:00:53 r_events.py:917 socket.send() raised exception.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!python train_model.py --config_path smolvla_omy.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20673462",
   "metadata": {},
   "source": [
    "## Step 3. Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07386e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import numpy as np\n",
    "from lerobot.common.datasets.utils import write_json, serialize_dict\n",
    "from lerobot.common.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "from lerobot.common.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.common.datasets.factory import resolve_delta_timestamps\n",
    "from lerobot.common.datasets.utils import dataset_to_policy_features\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1f651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381de80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./demo_data_language')\n",
    "except:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./omy_pnp_language')\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
    "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
    "# Temporal ensemble to make smoother trajectory predictions\n",
    "cfg = SmolVLAConfig(input_features=input_features, output_features=output_features, chunk_size= 5, n_action_steps=5)\n",
    "delta_timestamps = resolve_delta_timestamps(cfg, dataset_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e38030a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': './ckpt/smolvla_omy/checkpoints/last/pretrained_model'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We can now instantiate our policy with this config and the dataset stats.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[43mSmolVLAPolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./ckpt/smolvla_omy/checkpoints/last/pretrained_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# You can load the trained policy from hub if you don't have the resources to train it.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m policy\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/pretrained.py:97\u001b[0m, in \u001b[0;36mPreTrainedPolicy.from_pretrained\u001b[0;34m(cls, pretrained_name_or_path, config, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, strict, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mThe policy is set in evaluation mode by default using `policy.eval()` (dropout modules are\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03mdeactivated). To train it, you should first set it back in training mode with `policy.train()`.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mPreTrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pretrained_name_or_path)\n\u001b[1;32m    109\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/configs/policies.py:160\u001b[0m, in \u001b[0;36mPreTrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **policy_kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         config_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m HfHubHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found on the HuggingFace Hub in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be a string, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(repo_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The name cannot start or end with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and the maximum length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './ckpt/smolvla_omy/checkpoints/last/pretrained_model'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "# We can now instantiate our policy with this config and the dataset stats.\n",
    "policy = SmolVLAPolicy.from_pretrained('./ckpt/smolvla_omy/checkpoints/last/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      " n_qpos:[31] n_qvel:[28] n_qacc:[28] n_ctrl:[10]\n",
      " integrator:[IMPLICITFAST]\n",
      "\n",
      "n_body:[23]\n",
      " [0/23] [world] mass:[0.00]kg\n",
      " [1/23] [front_object_table] mass:[1.00]kg\n",
      " [2/23] [camera] mass:[0.00]kg\n",
      " [3/23] [camera2] mass:[0.00]kg\n",
      " [4/23] [camera3] mass:[0.00]kg\n",
      " [5/23] [link1] mass:[2.06]kg\n",
      " [6/23] [link2] mass:[3.68]kg\n",
      " [7/23] [link3] mass:[2.39]kg\n",
      " [8/23] [link4] mass:[1.40]kg\n",
      " [9/23] [link5] mass:[1.40]kg\n",
      " [10/23] [link6] mass:[0.65]kg\n",
      " [11/23] [camera_center] mass:[0.00]kg\n",
      " [12/23] [tcp_link] mass:[0.32]kg\n",
      " [13/23] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/23] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/23] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/23] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/23] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/23] [object_mug_5] mass:[0.08]kg\n",
      " [19/23] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/23] [object_plate_11] mass:[0.10]kg\n",
      " [21/23] [body_obj_mug_6] mass:[0.00]kg\n",
      " [22/23] [object_mug_6] mass:[0.08]kg\n",
      "body_total_mass:[13.35]kg\n",
      "\n",
      "n_geom:[116]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_mesh:[112]\n",
      "mesh_names:['base_unit', 'link1', 'link2', 'link3', 'link4', 'link5', 'link6', 'flange', 'base', 'r1', 'r2', 'l1', 'l2', 'mug_5_normalized_0_vis', 'mug_5_normalized_collision_22._coll', 'mug_5_normalized_collision_23._coll', 'mug_5_normalized_collision_21._coll', 'mug_5_normalized_collision_20._coll', 'mug_5_normalized_collision_24._coll', 'mug_5_normalized_collision_30._coll', 'mug_5_normalized_collision_18._coll', 'mug_5_normalized_collision_19._coll', 'mug_5_normalized_collision_31._coll', 'mug_5_normalized_collision_25._coll', 'mug_5_normalized_collision_27._coll', 'mug_5_normalized_collision_26._coll', 'mug_5_normalized_collision_9._coll', 'mug_5_normalized_collision_8._coll', 'mug_5_normalized_collision_6._coll', 'mug_5_normalized_collision_7._coll', 'mug_5_normalized_collision_5._coll', 'mug_5_normalized_collision_4._coll', 'mug_5_normalized_collision_0._coll', 'mug_5_normalized_collision_1._coll', 'mug_5_normalized_collision_3._coll', 'mug_5_normalized_collision_2._coll', 'mug_5_normalized_collision_17._coll', 'mug_5_normalized_collision_16._coll', 'mug_5_normalized_collision_28._coll', 'mug_5_normalized_collision_14._coll', 'mug_5_normalized_collision_15._coll', 'mug_5_normalized_collision_29._coll', 'mug_5_normalized_collision_11._coll', 'mug_5_normalized_collision_10._coll', 'mug_5_normalized_collision_12._coll', 'mug_5_normalized_collision_13._coll', 'plate_11_normalized_0_vis', 'plate_11_normalized_collision_22._coll', 'plate_11_normalized_collision_23._coll', 'plate_11_normalized_collision_21._coll', 'plate_11_normalized_collision_20._coll', 'plate_11_normalized_collision_24._coll', 'plate_11_normalized_collision_30._coll', 'plate_11_normalized_collision_18._coll', 'plate_11_normalized_collision_19._coll', 'plate_11_normalized_collision_31._coll', 'plate_11_normalized_collision_25._coll', 'plate_11_normalized_collision_27._coll', 'plate_11_normalized_collision_26._coll', 'plate_11_normalized_collision_9._coll', 'plate_11_normalized_collision_8._coll', 'plate_11_normalized_collision_6._coll', 'plate_11_normalized_collision_7._coll', 'plate_11_normalized_collision_5._coll', 'plate_11_normalized_collision_4._coll', 'plate_11_normalized_collision_0._coll', 'plate_11_normalized_collision_1._coll', 'plate_11_normalized_collision_3._coll', 'plate_11_normalized_collision_2._coll', 'plate_11_normalized_collision_17._coll', 'plate_11_normalized_collision_16._coll', 'plate_11_normalized_collision_28._coll', 'plate_11_normalized_collision_14._coll', 'plate_11_normalized_collision_15._coll', 'plate_11_normalized_collision_29._coll', 'plate_11_normalized_collision_11._coll', 'plate_11_normalized_collision_10._coll', 'plate_11_normalized_collision_12._coll', 'plate_11_normalized_collision_13._coll', 'mug_6_normalized_0_vis', 'mug_6_normalized_collision_22._coll', 'mug_6_normalized_collision_23._coll', 'mug_6_normalized_collision_21._coll', 'mug_6_normalized_collision_20._coll', 'mug_6_normalized_collision_24._coll', 'mug_6_normalized_collision_30._coll', 'mug_6_normalized_collision_18._coll', 'mug_6_normalized_collision_19._coll', 'mug_6_normalized_collision_31._coll', 'mug_6_normalized_collision_25._coll', 'mug_6_normalized_collision_27._coll', 'mug_6_normalized_collision_26._coll', 'mug_6_normalized_collision_9._coll', 'mug_6_normalized_collision_8._coll', 'mug_6_normalized_collision_6._coll', 'mug_6_normalized_collision_7._coll', 'mug_6_normalized_collision_5._coll', 'mug_6_normalized_collision_4._coll', 'mug_6_normalized_collision_0._coll', 'mug_6_normalized_collision_1._coll', 'mug_6_normalized_collision_3._coll', 'mug_6_normalized_collision_2._coll', 'mug_6_normalized_collision_17._coll', 'mug_6_normalized_collision_16._coll', 'mug_6_normalized_collision_28._coll', 'mug_6_normalized_collision_14._coll', 'mug_6_normalized_collision_15._coll', 'mug_6_normalized_collision_29._coll', 'mug_6_normalized_collision_11._coll', 'mug_6_normalized_collision_10._coll', 'mug_6_normalized_collision_12._coll', 'mug_6_normalized_collision_13._coll']\n",
      "\n",
      "n_joint:[13]\n",
      " [0/13] [joint1] axis:[0. 0. 1.]\n",
      " [1/13] [joint2] axis:[0. 1. 0.]\n",
      " [2/13] [joint3] axis:[0. 1. 0.]\n",
      " [3/13] [joint4] axis:[0. 1. 0.]\n",
      " [4/13] [joint5] axis:[0. 0. 1.]\n",
      " [5/13] [joint6] axis:[0. 1. 0.]\n",
      " [6/13] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/13] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/13] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/13] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/13] [None] axis:[0. 0. 1.]\n",
      " [11/13] [None] axis:[0. 0. 1.]\n",
      " [12/13] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[28] (=number of rows of Jacobian)\n",
      " [0/28] [None] attached joint:[joint1] body:[link1]\n",
      " [1/28] [None] attached joint:[joint2] body:[link2]\n",
      " [2/28] [None] attached joint:[joint3] body:[link3]\n",
      " [3/28] [None] attached joint:[joint4] body:[link4]\n",
      " [4/28] [None] attached joint:[joint5] body:[link5]\n",
      " [5/28] [None] attached joint:[joint6] body:[link6]\n",
      " [6/28] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/28] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/28] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/28] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [22/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [23/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [24/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [25/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [26/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [27/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      "\n",
      "Free joint information. n_free_joint:[3]\n",
      " [0/3] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/3] [None] body_name_attached:[body_obj_plate_11]\n",
      " [2/3] [None] body_name_attached:[body_obj_mug_6]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[9]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11', 'bottom_site_mug_6', 'top_site_mug_6', 'horizontal_radius_site_mug_6']\n",
      "-----------------------------------------------------------------------------\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "from mujoco_env.y_env2 import SimpleEnv2\n",
    "xml_path = './asset/example_scene_y2.xml'\n",
    "PnPEnv = SimpleEnv2(xml_path, action_type='joint_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db761f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Approach 1: Using torchvision.transforms\n",
    "def get_default_transform(image_size: int = 224):\n",
    "    \"\"\"\n",
    "    Returns a torchvision transform that:\n",
    "     Converts to a FloatTensor and scales pixel values [0,255] -> [0.0,1.0]\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL [0–255] -> FloatTensor [0.0–1.0], shape C×H×W\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3326535/3859105902.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  'observation.state': torch.tensor([state]).to(device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "PnPEnv.reset(seed=0)\n",
    "policy.reset()\n",
    "policy.eval()\n",
    "save_image = True\n",
    "IMG_TRANSFORM = get_default_transform()\n",
    "while PnPEnv.env.is_viewer_alive():\n",
    "    PnPEnv.step_env()\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        # Check if the task is completed\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            # Reset the environment and action queue\n",
    "            policy.reset()\n",
    "            PnPEnv.reset()\n",
    "            step = 0\n",
    "            save_image = False\n",
    "        # Get the current state of the environment\n",
    "        state = PnPEnv.get_joint_state()[:6]\n",
    "        # Get the current image from the environment\n",
    "        image, wirst_image = PnPEnv.grab_image()\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((256, 256))\n",
    "        image = IMG_TRANSFORM(image)\n",
    "        wrist_image = Image.fromarray(wirst_image)\n",
    "        wrist_image = wrist_image.resize((256, 256))\n",
    "        wrist_image = IMG_TRANSFORM(wrist_image)\n",
    "        data = {\n",
    "            'observation.state': torch.tensor([state]).to(device),\n",
    "            'observation.image': image.unsqueeze(0).to(device),\n",
    "            'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
    "            'task': [PnPEnv.instruction],\n",
    "        }\n",
    "        # Select an action\n",
    "        action = policy.select_action(data)\n",
    "        action = action[0,:7].cpu().detach().numpy()\n",
    "        # Take a step in the environment\n",
    "        _ = PnPEnv.step(action)\n",
    "        PnPEnv.render()\n",
    "        step += 1\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b593df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.20G/1.20G [02:26<00:00, 8.19MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Jeongeun/omy_pnp_smolvla/commit/738e2cb9235562d58842ceb8a9469ae21278bb53', commit_message='Add trained policy for PnP task', commit_description='', oid='738e2cb9235562d58842ceb8a9469ae21278bb53', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Jeongeun/omy_pnp_smolvla', endpoint='https://huggingface.co', repo_type='model', repo_id='Jeongeun/omy_pnp_smolvla'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# policy.push_to_hub(\n",
    "#     repo_id='Jeongeun/omy_pnp_smolvla',\n",
    "#     commit_message='Add trained policy for PnP task',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb9032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
