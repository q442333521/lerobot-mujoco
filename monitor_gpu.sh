#!/bin/bash
# ===================================================
# GPU and Training Monitor
# GPUå’Œè®­ç»ƒç›‘æ§è„šæœ¬
# ===================================================

echo "=================================================="
echo "ğŸ“Š System Monitor | ç³»ç»Ÿç›‘æ§"
echo "=================================================="
echo ""

while true; do
    clear
    echo "ğŸ–¥ï¸  GPU Status | GPUçŠ¶æ€"
    echo "=================================================="
    nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total,temperature.gpu \
               --format=csv,noheader,nounits | \
    awk -F, '{printf "GPU %s: %s\n  Utilization: %s%%\n  Memory: %sMB / %sMB (%.1f%%)\n  Temp: %sÂ°C\n\n", 
             $1, $2, $3, $4, $5, ($4/$5*100), $6}'
    
    echo "=================================================="
    echo "ğŸ’¾ Training Process | è®­ç»ƒè¿›ç¨‹"
    echo "=================================================="
    
    # æŸ¥æ‰¾è®­ç»ƒè¿›ç¨‹ Find training process
    train_pid=$(pgrep -f "train_model.py")
    if [ ! -z "$train_pid" ]; then
        echo "âœ“ Training is running | è®­ç»ƒæ­£åœ¨è¿›è¡Œ"
        echo "  PID: $train_pid"
        
        # æ˜¾ç¤ºCPUå’Œå†…å­˜ä½¿ç”¨ Show CPU and memory usage
        ps -p $train_pid -o %cpu,%mem,etime,cmd --no-headers | \
        awk '{printf "  CPU: %s%%\n  Memory: %s%%\n  Runtime: %s\n", $1, $2, $3}'
        
        # æ˜¾ç¤ºæœ€æ–°çš„loss (ä»æ—¥å¿—æ–‡ä»¶è¯»å–)
        if [ -f "ckpt/smolvla_omy/training.log" ]; then
            echo ""
            echo "ğŸ“ˆ Latest Training Info | æœ€æ–°è®­ç»ƒä¿¡æ¯"
            tail -n 1 ckpt/smolvla_omy/training.log 2>/dev/null || echo "  Log file not found"
        fi
    else
        echo "âš ï¸  No training process found | æœªæ‰¾åˆ°è®­ç»ƒè¿›ç¨‹"
    fi
    
    echo ""
    echo "=================================================="
    echo "Press Ctrl+C to exit | æŒ‰ Ctrl+C é€€å‡º"
    echo "Refreshing in 5 seconds... | 5ç§’ååˆ·æ–°..."
    
    sleep 5
done
