{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371659c1",
   "metadata": {},
   "source": [
    "# Collect Demonstration from Keyboard\n",
    "\n",
    "Collect demonstration data for the given environment.\n",
    "The task is to pick a mug and place it on the plate. The environment recognizes the success if the mug is on the plate, gthe ripper opened, and the end-effector positioned above the mug.\n",
    "\n",
    "<img src=\"./media/teleop_v2.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Use WASD for the xy plane, RF for the z-axis, QE for tilt, and ARROWs for the rest of rthe otations. \n",
    "\n",
    "SPACEBAR will change your gripper's state, and Z key will reset your environment with discarding the current episode data.\n",
    "\n",
    "For overlayed images, \n",
    "- Top Right: Agent View \n",
    "- Bottom Right: Egocentric View\n",
    "- Top Left: Left Side View\n",
    "- Bottom Left: Top View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be380163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DISPLAY设置为: :0\n",
      "✓ MUJOCO_GL: egl (GPU硬件加速)\n",
      "✓ NVIDIA GPU优化已启用\n",
      "✓ OpenGL性能优化已启用\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - 设置环境变量（必须第一个运行）\n",
    "import os\n",
    "\n",
    "# 1. 设置DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"✓ DISPLAY设置为: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. 强制使用GPU渲染（关键！）\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGL后端GPU加速\n",
    "print(f\"✓ MUJOCO_GL: egl (GPU硬件加速)\")\n",
    "\n",
    "# 3. NVIDIA GPU优化\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # 关闭垂直同步\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # 减少CPU等待\n",
    "print(\"✓ NVIDIA GPU优化已启用\")\n",
    "\n",
    "# 4. OpenGL性能优化\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # 关闭抗锯齿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # 关闭各向异性过滤\n",
    "print(\"✓ OpenGL性能优化已启用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a4fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from mujoco_env.y_env2 import SimpleEnv2\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ecde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to randomize the object positions, set this to None\n",
    "# If you fix the seed, the object positions will be the same every time\n",
    "SEED = 0 \n",
    "# SEED = None <- Uncomment this line to randomize the object positions\n",
    "\n",
    "REPO_NAME = 'omy_pnp_language'\n",
    "NUM_DEMO = 20 # Number of demonstrations to collect\n",
    "ROOT = \"./251103-myself_data_language\" # The root directory to save the demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00198f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      " n_qpos:[31] n_qvel:[28] n_qacc:[28] n_ctrl:[10]\n",
      " integrator:[IMPLICITFAST]\n",
      "\n",
      "n_body:[23]\n",
      " [0/23] [world] mass:[0.00]kg\n",
      " [1/23] [front_object_table] mass:[1.00]kg\n",
      " [2/23] [camera] mass:[0.00]kg\n",
      " [3/23] [camera2] mass:[0.00]kg\n",
      " [4/23] [camera3] mass:[0.00]kg\n",
      " [5/23] [link1] mass:[2.06]kg\n",
      " [6/23] [link2] mass:[3.68]kg\n",
      " [7/23] [link3] mass:[2.39]kg\n",
      " [8/23] [link4] mass:[1.40]kg\n",
      " [9/23] [link5] mass:[1.40]kg\n",
      " [10/23] [link6] mass:[0.65]kg\n",
      " [11/23] [camera_center] mass:[0.00]kg\n",
      " [12/23] [tcp_link] mass:[0.32]kg\n",
      " [13/23] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/23] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/23] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/23] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/23] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/23] [object_mug_5] mass:[0.08]kg\n",
      " [19/23] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/23] [object_plate_11] mass:[0.10]kg\n",
      " [21/23] [body_obj_mug_6] mass:[0.00]kg\n",
      " [22/23] [object_mug_6] mass:[0.08]kg\n",
      "body_total_mass:[13.35]kg\n",
      "\n",
      "n_geom:[116]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_mesh:[112]\n",
      "mesh_names:['base_unit', 'link1', 'link2', 'link3', 'link4', 'link5', 'link6', 'flange', 'base', 'r1', 'r2', 'l1', 'l2', 'mug_5_normalized_0_vis', 'mug_5_normalized_collision_22._coll', 'mug_5_normalized_collision_23._coll', 'mug_5_normalized_collision_21._coll', 'mug_5_normalized_collision_20._coll', 'mug_5_normalized_collision_24._coll', 'mug_5_normalized_collision_30._coll', 'mug_5_normalized_collision_18._coll', 'mug_5_normalized_collision_19._coll', 'mug_5_normalized_collision_31._coll', 'mug_5_normalized_collision_25._coll', 'mug_5_normalized_collision_27._coll', 'mug_5_normalized_collision_26._coll', 'mug_5_normalized_collision_9._coll', 'mug_5_normalized_collision_8._coll', 'mug_5_normalized_collision_6._coll', 'mug_5_normalized_collision_7._coll', 'mug_5_normalized_collision_5._coll', 'mug_5_normalized_collision_4._coll', 'mug_5_normalized_collision_0._coll', 'mug_5_normalized_collision_1._coll', 'mug_5_normalized_collision_3._coll', 'mug_5_normalized_collision_2._coll', 'mug_5_normalized_collision_17._coll', 'mug_5_normalized_collision_16._coll', 'mug_5_normalized_collision_28._coll', 'mug_5_normalized_collision_14._coll', 'mug_5_normalized_collision_15._coll', 'mug_5_normalized_collision_29._coll', 'mug_5_normalized_collision_11._coll', 'mug_5_normalized_collision_10._coll', 'mug_5_normalized_collision_12._coll', 'mug_5_normalized_collision_13._coll', 'plate_11_normalized_0_vis', 'plate_11_normalized_collision_22._coll', 'plate_11_normalized_collision_23._coll', 'plate_11_normalized_collision_21._coll', 'plate_11_normalized_collision_20._coll', 'plate_11_normalized_collision_24._coll', 'plate_11_normalized_collision_30._coll', 'plate_11_normalized_collision_18._coll', 'plate_11_normalized_collision_19._coll', 'plate_11_normalized_collision_31._coll', 'plate_11_normalized_collision_25._coll', 'plate_11_normalized_collision_27._coll', 'plate_11_normalized_collision_26._coll', 'plate_11_normalized_collision_9._coll', 'plate_11_normalized_collision_8._coll', 'plate_11_normalized_collision_6._coll', 'plate_11_normalized_collision_7._coll', 'plate_11_normalized_collision_5._coll', 'plate_11_normalized_collision_4._coll', 'plate_11_normalized_collision_0._coll', 'plate_11_normalized_collision_1._coll', 'plate_11_normalized_collision_3._coll', 'plate_11_normalized_collision_2._coll', 'plate_11_normalized_collision_17._coll', 'plate_11_normalized_collision_16._coll', 'plate_11_normalized_collision_28._coll', 'plate_11_normalized_collision_14._coll', 'plate_11_normalized_collision_15._coll', 'plate_11_normalized_collision_29._coll', 'plate_11_normalized_collision_11._coll', 'plate_11_normalized_collision_10._coll', 'plate_11_normalized_collision_12._coll', 'plate_11_normalized_collision_13._coll', 'mug_6_normalized_0_vis', 'mug_6_normalized_collision_22._coll', 'mug_6_normalized_collision_23._coll', 'mug_6_normalized_collision_21._coll', 'mug_6_normalized_collision_20._coll', 'mug_6_normalized_collision_24._coll', 'mug_6_normalized_collision_30._coll', 'mug_6_normalized_collision_18._coll', 'mug_6_normalized_collision_19._coll', 'mug_6_normalized_collision_31._coll', 'mug_6_normalized_collision_25._coll', 'mug_6_normalized_collision_27._coll', 'mug_6_normalized_collision_26._coll', 'mug_6_normalized_collision_9._coll', 'mug_6_normalized_collision_8._coll', 'mug_6_normalized_collision_6._coll', 'mug_6_normalized_collision_7._coll', 'mug_6_normalized_collision_5._coll', 'mug_6_normalized_collision_4._coll', 'mug_6_normalized_collision_0._coll', 'mug_6_normalized_collision_1._coll', 'mug_6_normalized_collision_3._coll', 'mug_6_normalized_collision_2._coll', 'mug_6_normalized_collision_17._coll', 'mug_6_normalized_collision_16._coll', 'mug_6_normalized_collision_28._coll', 'mug_6_normalized_collision_14._coll', 'mug_6_normalized_collision_15._coll', 'mug_6_normalized_collision_29._coll', 'mug_6_normalized_collision_11._coll', 'mug_6_normalized_collision_10._coll', 'mug_6_normalized_collision_12._coll', 'mug_6_normalized_collision_13._coll']\n",
      "\n",
      "n_joint:[13]\n",
      " [0/13] [joint1] axis:[0. 0. 1.]\n",
      " [1/13] [joint2] axis:[0. 1. 0.]\n",
      " [2/13] [joint3] axis:[0. 1. 0.]\n",
      " [3/13] [joint4] axis:[0. 1. 0.]\n",
      " [4/13] [joint5] axis:[0. 0. 1.]\n",
      " [5/13] [joint6] axis:[0. 1. 0.]\n",
      " [6/13] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/13] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/13] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/13] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/13] [None] axis:[0. 0. 1.]\n",
      " [11/13] [None] axis:[0. 0. 1.]\n",
      " [12/13] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[28] (=number of rows of Jacobian)\n",
      " [0/28] [None] attached joint:[joint1] body:[link1]\n",
      " [1/28] [None] attached joint:[joint2] body:[link2]\n",
      " [2/28] [None] attached joint:[joint3] body:[link3]\n",
      " [3/28] [None] attached joint:[joint4] body:[link4]\n",
      " [4/28] [None] attached joint:[joint5] body:[link5]\n",
      " [5/28] [None] attached joint:[joint6] body:[link6]\n",
      " [6/28] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/28] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/28] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/28] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [22/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [23/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [24/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [25/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [26/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [27/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      "\n",
      "Free joint information. n_free_joint:[3]\n",
      " [0/3] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/3] [None] body_name_attached:[body_obj_plate_11]\n",
      " [2/3] [None] body_name_attached:[body_obj_mug_6]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[9]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11', 'bottom_site_mug_6', 'top_site_mug_6', 'horizontal_radius_site_mug_6']\n",
      "-----------------------------------------------------------------------------\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "xml_path = './asset/example_scene_y2.xml'\n",
    "# Define the environment\n",
    "PnPEnv = SimpleEnv2(xml_path, seed = SEED, state_type = 'joint_angle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1da1e",
   "metadata": {},
   "source": [
    "## Define Dataset Fatures and Create your dataset!\n",
    "The dataset is contained as follows:\n",
    "```\n",
    "fps = 20,\n",
    "features={\n",
    "    \"observation.image\": {\n",
    "        \"dtype\": \"image\",\n",
    "        \"shape\": (256, 256, 3),\n",
    "        \"names\": [\"height\", \"width\", \"channels\"],\n",
    "    },\n",
    "    \"observation.wrist_image\": {\n",
    "        \"dtype\": \"image\",\n",
    "        \"shape\": (256, 256, 3),\n",
    "        \"names\": [\"height\", \"width\", \"channel\"],\n",
    "    },\n",
    "    \"observation.state\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (6,),\n",
    "        \"names\": [\"state\"], # x, y, z, roll, pitch, yaw\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (7,),\n",
    "        \"names\": [\"action\"], # 6 joint angles and 1 gripper\n",
    "    },\n",
    "    \"obj_init\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (6,),\n",
    "        \"names\": [\"obj_init\"], # just the initial position of the object. Not used in training.\n",
    "    },\n",
    "},\n",
    "```\n",
    "\n",
    "\n",
    "This will make the dataset on './demo_data' folder, which will look like this,\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── chunk-000\n",
    "│   │   ├── episode_000000.parquet\n",
    "│   │   └── ...\n",
    "├── meta\n",
    "│   ├── episodes.jsonl\n",
    "│   ├── info.json\n",
    "│   ├── stats.json\n",
    "│   └── tasks.jsonl\n",
    "└── \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c68153b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./demo_data_language already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Process Process-7:\n",
      "Process Process-8:\n",
      "Process Process-6:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/datasets/image_writer.py\", line 103, in worker_process\n",
      "    t.join()\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/datasets/image_writer.py\", line 103, in worker_process\n",
      "    t.join()\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/datasets/image_writer.py\", line 103, in worker_process\n",
      "    t.join()\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/datasets/image_writer.py\", line 103, in worker_process\n",
      "    t.join()\n",
      "  File \"/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/datasets/image_writer.py\", line 103, in worker_process\n",
      "    t.join()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "create_new = True\n",
    "if os.path.exists(ROOT):\n",
    "    print(f\"Directory {ROOT} already exists.\")\n",
    "    ans = input(\"Do you want to delete it? (y/n) \")\n",
    "    if ans == 'y':\n",
    "        import shutil\n",
    "        shutil.rmtree(ROOT)\n",
    "    else:\n",
    "        create_new = False\n",
    "\n",
    "\n",
    "if create_new:\n",
    "    dataset = LeRobotDataset.create(\n",
    "                repo_id=REPO_NAME,\n",
    "                root = ROOT, \n",
    "                robot_type=\"omy\",\n",
    "                fps=20, # 20 frames per second\n",
    "                features={\n",
    "                    \"observation.image\": {\n",
    "                        \"dtype\": \"image\",\n",
    "                        \"shape\": (256, 256, 3),\n",
    "                        \"names\": [\"height\", \"width\", \"channels\"],\n",
    "                    },\n",
    "                    \"observation.wrist_image\": {\n",
    "                        \"dtype\": \"image\",\n",
    "                        \"shape\": (256, 256, 3),\n",
    "                        \"names\": [\"height\", \"width\", \"channel\"],\n",
    "                    },\n",
    "                    \"observation.state\": {\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": (6,),\n",
    "                        \"names\": [\"state\"], # x, y, z, roll, pitch, yaw\n",
    "                    },\n",
    "                    \"action\": {\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": (7,),\n",
    "                        \"names\": [\"action\"], # 6 joint angles and 1 gripper\n",
    "                    },\n",
    "                    \"obj_init\": {\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": (9,),\n",
    "                        \"names\": [\"obj_init\"], # just the initial position of the object. Not used in training.\n",
    "                    },\n",
    "                },\n",
    "                image_writer_threads=10,\n",
    "                image_writer_processes=5,\n",
    "        )\n",
    "else:\n",
    "    print(\"Load from previous dataset\")\n",
    "    dataset = LeRobotDataset(REPO_NAME, root=ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fbab41",
   "metadata": {},
   "source": [
    "## Keyboard Control\n",
    "You can teleop your robot with keyboard and collect dataset\n",
    "```\n",
    "---------     -----------------------\n",
    "   w       ->        backward\n",
    "s  a  d        left   forward   right\n",
    "---------      -----------------------\n",
    "In x, y plane\n",
    "\n",
    "---------\n",
    "R: Moving Up\n",
    "F: Moving Down\n",
    "---------\n",
    "In z axis\n",
    "\n",
    "---------\n",
    "Q: Tilt left\n",
    "E: Tilt right\n",
    "UP: Look Upward\n",
    "Down: Look Donward\n",
    "Right: Turn right\n",
    "Left: Turn left\n",
    "---------\n",
    "For rotation\n",
    "\n",
    "---------\n",
    "SPACEBAR: Toggle Gripper\n",
    "--------\n",
    "\n",
    "---------\n",
    "z: reset\n",
    "--------\n",
    "```\n",
    "Reseting your environment will remove the cache data of the current demonstration and restart collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f8b99",
   "metadata": {},
   "source": [
    "### Now let's teleop our robot and collect data!\n",
    "\n",
    "**To receive the success signal, you have to release the gripper and move upwards above the mug!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b080011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 651/651 [00:00<00:00, 1211.12 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 99.29ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 458/458 [00:00<00:00, 1265.54 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 72.39ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 392/392 [00:00<00:00, 1250.40 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 69.12ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 424/424 [00:00<00:00, 1299.61 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 83.91ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 322/322 [00:00<00:00, 1353.74 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 85.21ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 293/293 [00:00<00:00, 1407.61 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 70.32ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 410/410 [00:00<00:00, 1362.64 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 94.17ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 381/381 [00:00<00:00, 1353.34 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 72.50ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 275/275 [00:00<00:00, 1395.38 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 74.62ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 406/406 [00:00<00:00, 1326.82 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 125.52ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1245/1245 [00:00<00:00, 1339.11 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:00<00:00, 216.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 284/284 [00:00<00:00, 1363.15 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 72.18ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 595/595 [00:00<00:00, 1291.41 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 75.58ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 248/248 [00:00<00:00, 1496.18 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 86.09ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 220/220 [00:00<00:00, 1461.92 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 90.21ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n",
      "DONE INITIALIZATION\n",
      "Start recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 327/327 [00:00<00:00, 1435.86 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 87.30ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# ===== 图像预处理 =====\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 将numpy数组转换为PIL Image对象，方便进行resize操作\u001b[39;00m\n\u001b[1;32m     63\u001b[0m agent_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(agent_image)\n\u001b[0;32m---> 64\u001b[0m wrist_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrist_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 将图像统一调整为256x256的尺寸\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 这是为了满足后续神经网络模型的输入要求\u001b[39;00m\n\u001b[1;32m     68\u001b[0m agent_image \u001b[38;5;241m=\u001b[39m agent_image\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/PIL/Image.py:3309\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtobytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3309\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3310\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtostring\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   3311\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 初始化一个7维的动作向量（全为0）\n",
    "# 这7个维度包括：6个机器人关节角度 + 1个夹爪开合状态\n",
    "action = np.zeros(7)\n",
    "\n",
    "# 当前演示回合的编号，从0开始计数\n",
    "episode_id = 0\n",
    "\n",
    "# 记录标志位：用于控制何时开始记录数据\n",
    "# False表示还未开始记录，当机器人开始移动时才设为True\n",
    "record_flag = False  # Start recording when the robot starts moving\n",
    "\n",
    "# 主循环：持续运行直到以下任一条件不满足\n",
    "# 1. 仿真查看器窗口还在运行\n",
    "# 2. 已收集的演示数量还未达到目标数量NUM_DEMO\n",
    "while PnPEnv.env.is_viewer_alive() and episode_id < NUM_DEMO:\n",
    "    \n",
    "    # 推进环境一步（更新物理仿真）\n",
    "    PnPEnv.step_env()\n",
    "    \n",
    "    # 控制主循环频率为20Hz（每秒执行20次）\n",
    "    # 这样可以避免执行太快导致数据采集过密\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        \n",
    "        # ===== 检查任务完成状态 =====\n",
    "        done = PnPEnv.check_success()\n",
    "        if done:  # 如果任务成功完成\n",
    "            # 保存当前回合的所有数据到数据集\n",
    "            dataset.save_episode()\n",
    "            # 重置环境，准备下一个回合\n",
    "            PnPEnv.reset()\n",
    "            # 回合计数器加1\n",
    "            episode_id += 1\n",
    "        \n",
    "        # ===== 遥操作控制 =====\n",
    "        # 通过遥操作设备（如键盘、手柄等）控制机器人\n",
    "        # action: 末端执行器的增量姿态变化 + 夹爪状态\n",
    "        # reset: 是否按下了重置键（如'z'键）\n",
    "        action, reset = PnPEnv.teleop_robot()\n",
    "        \n",
    "        # 判断是否应该开始记录数据\n",
    "        # 条件：还未开始记录 且 有实际动作输入（action不全为0）\n",
    "        if not record_flag and sum(action) != 0:\n",
    "            record_flag = True\n",
    "            print(\"Start recording\")  # 提示开始记录\n",
    "        \n",
    "        # 如果用户按下了重置键\n",
    "        if reset:\n",
    "            # 重置环境到初始状态\n",
    "            PnPEnv.reset()\n",
    "            # 清空当前回合的缓冲数据（丢弃失败的尝试）\n",
    "            dataset.clear_episode_buffer()\n",
    "            # 停止记录\n",
    "            record_flag = False\n",
    "        \n",
    "        # ===== 获取观测数据 =====\n",
    "        # 从两个摄像头获取RGB图像\n",
    "        # agent_image: 第三人称视角的图像（固定摄像头）\n",
    "        # wrist_image: 第一人称视角的图像（安装在机械臂腕部的摄像头）\n",
    "        agent_image, wrist_image = PnPEnv.grab_image()\n",
    "        \n",
    "        # ===== 图像预处理 =====\n",
    "        # 将numpy数组转换为PIL Image对象，方便进行resize操作\n",
    "        agent_image = Image.fromarray(agent_image)\n",
    "        wrist_image = Image.fromarray(wrist_image)\n",
    "        \n",
    "        # 将图像统一调整为256x256的尺寸\n",
    "        # 这是为了满足后续神经网络模型的输入要求\n",
    "        agent_image = agent_image.resize((256, 256))\n",
    "        wrist_image = wrist_image.resize((256, 256))\n",
    "        \n",
    "        # 将PIL Image转回numpy数组，用于数据存储\n",
    "        agent_image = np.array(agent_image)\n",
    "        wrist_image = np.array(wrist_image)\n",
    "        \n",
    "        # ===== 执行动作并获取机器人状态 =====\n",
    "        # 让机器人执行action对应的动作，并返回当前关节角度\n",
    "        joint_q = PnPEnv.step(action)\n",
    "        \n",
    "        # 获取实际的机器人状态（7维）\n",
    "        # PnPEnv.q包含了机器人的完整状态，取前7个维度\n",
    "        # 这7个维度是：6个关节的实际角度 + 1个夹爪的实际开合度\n",
    "        action = PnPEnv.q[:7]\n",
    "        \n",
    "        # 转换为float32类型，节省存储空间\n",
    "        action = action.astype(np.float32)\n",
    "        \n",
    "        # ===== 数据记录 =====\n",
    "        # 只有在record_flag为True时才记录数据\n",
    "        # 这样可以避免记录机器人静止不动时的无效数据\n",
    "        if record_flag:\n",
    "            # 将当前帧的所有数据添加到数据集\n",
    "            dataset.add_frame({\n",
    "                \"observation.image\": agent_image,        # 第三人称视角图像\n",
    "                \"observation.wrist_image\": wrist_image,  # 第一人称视角图像\n",
    "                \"observation.state\": joint_q[:6],        # 机器人状态（6个关节角度）\n",
    "                \"action\": action,                         # 动作（7维：6关节+1夹爪）\n",
    "                \"obj_init\": PnPEnv.obj_init_pose,       # 物体初始位姿\n",
    "                # \"task\": PnPEnv.instruction,            # 任务描述（已注释）\n",
    "            }, task=PnPEnv.instruction  # 任务指令（如\"pick and place\"）\n",
    "            )\n",
    "        \n",
    "        # ===== 可视化渲染 =====\n",
    "        # 更新仿真环境的可视化界面\n",
    "        # teleop=True: 表示当前处于遥操作模式\n",
    "        # idx=episode_id: 显示当前回合编号\n",
    "        PnPEnv.render(teleop=True, idx=episode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e2b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce04f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the images folder\n",
    "import shutil\n",
    "shutil.rmtree(dataset.root / 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0e170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
